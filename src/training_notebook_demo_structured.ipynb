{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qPaUL1ZltkFd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import datetime\n",
        "import gymnasium as gym\n",
        "from gymnasium.spaces import Discrete, MultiDiscrete\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import random\n",
        "import copy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from collections import deque, defaultdict\n",
        "from tqdm import tqdm\n",
        "from train import AlphaLoss, train_pipeline\n",
        "from environments import FrozenLakeManipulationEnv, GripperDiscretisedEnv\n",
        "from data_loading import to_one_hot_encoding, ReplayBuffer, ReplayDataset\n",
        "from mcts_models import MCTSNode, LearnedMCTSNode, AlphaZeroNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "w9RZ1UOrtkFg"
      },
      "outputs": [],
      "source": [
        "# MCTS / AlphaZero params\n",
        "NUM_SIMS     = 10000       # MCTS simulations/iterations per self-play step\n",
        "NUM_SELF_PLAY = 1       # number of self-play games to generate per epoch/episode\n",
        "NUM_EPOCHS   = 10       # number of epochs to train the model\n",
        "CPUCT        = 1.41       # PUCT exploration constant\n",
        "TAU          = 1.0       # temperature for π = N^(1/τ)\n",
        "# Training params\n",
        "BATCH_SIZE   = 128\n",
        "LR           = 1e-3\n",
        "EVAL_INTERVAL= 1       # eval every self-play games\n",
        "TARGET_SR    = 0.90      # stop when success rate ≥ 95%\n",
        "REGULARIZATION = 1e-4    # L2 regularization weight decay constant\n",
        "MAX_EPISODES = 10 \n",
        "\n",
        "NUM_EVAL     = 50\n",
        "BUFFER_SIZE   = 20000\n",
        "SAMPLE_SIZE   = 2048"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxPpY3j7tkFh",
        "outputId": "df0d9156-ce4a-483c-ffa3-228592439574"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "# --- Main Execution ---\n",
        "def make_env():\n",
        "    # return gym.make(\"FrozenLake-v1\", is_slippery=False, render_mode=\"ansi\")\n",
        "    return FrozenLakeManipulationEnv()\n",
        "    # return GripperDiscretisedEnv()\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "env    = make_env()\n",
        "env.reset()\n",
        "state, info = env.reset()\n",
        "nA = env.action_space.n\n",
        "\n",
        "if isinstance(env.observation_space, Discrete):\n",
        "    nS = env.observation_space.n\n",
        "else:\n",
        "    # Assuming the observation space is a tuple of (states, ..., states, holding/not_holding) \n",
        "    nS = (len(env.observation_space.sample()) - 1) * env.n_states + 1\n",
        "net    = AlphaZeroNet(nS, nA).to(device)\n",
        "optimizer   = optim.Adam(net.parameters(), lr=LR, weight_decay=REGULARIZATION)\n",
        "scheduler   = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "root_node = LearnedMCTSNode(state=state,\n",
        "                            make_env=make_env,\n",
        "                            net=net,\n",
        "                            cpuct=CPUCT,\n",
        "                            device=device,\n",
        "                            verbose=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Episode 1/10:   0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Episode 1/10:  20%|██        | 2/10 [00:26<01:47, 13.47s/it, buffer=4, reward=-1]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_pipeline(net\u001b[38;5;241m=\u001b[39mnet,\n\u001b[1;32m      2\u001b[0m                 make_env\u001b[38;5;241m=\u001b[39mmake_env,\n\u001b[1;32m      3\u001b[0m                 optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[1;32m      4\u001b[0m                 scheduler\u001b[38;5;241m=\u001b[39mscheduler,\n\u001b[1;32m      5\u001b[0m                 buffer_size\u001b[38;5;241m=\u001b[39mBUFFER_SIZE,\n\u001b[1;32m      6\u001b[0m                 sample_size\u001b[38;5;241m=\u001b[39mSAMPLE_SIZE,\n\u001b[1;32m      7\u001b[0m                 batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE,\n\u001b[1;32m      8\u001b[0m                 num_sims\u001b[38;5;241m=\u001b[39mNUM_SIMS,\n\u001b[1;32m      9\u001b[0m                 num_epochs\u001b[38;5;241m=\u001b[39mNUM_EPOCHS,\n\u001b[1;32m     10\u001b[0m                 tau\u001b[38;5;241m=\u001b[39mTAU,\n\u001b[1;32m     11\u001b[0m                 cpuct\u001b[38;5;241m=\u001b[39mCPUCT,\n\u001b[1;32m     12\u001b[0m                 num_episodes\u001b[38;5;241m=\u001b[39mMAX_EPISODES,\n\u001b[1;32m     13\u001b[0m                 num_self_play\u001b[38;5;241m=\u001b[39mNUM_SELF_PLAY,\n\u001b[1;32m     14\u001b[0m                 eval_interval\u001b[38;5;241m=\u001b[39mEVAL_INTERVAL,\n\u001b[1;32m     15\u001b[0m                 num_eval\u001b[38;5;241m=\u001b[39mNUM_EVAL,\n\u001b[1;32m     16\u001b[0m                 target_sr\u001b[38;5;241m=\u001b[39mTARGET_SR,\n\u001b[1;32m     17\u001b[0m                 device\u001b[38;5;241m=\u001b[39mdevice)\n",
            "File \u001b[0;32m~/Desktop/UoEYear5/laas/monte-carlo-manipulation/src/train.py:298\u001b[0m, in \u001b[0;36mtrain_pipeline\u001b[0;34m(net, make_env, optimizer, scheduler, buffer_size, sample_size, batch_size, num_sims, num_epochs, tau, cpuct, num_episodes, num_self_play, eval_interval, num_eval, target_sr, device, verbose)\u001b[0m\n\u001b[1;32m    293\u001b[0m self_play_bar \u001b[38;5;241m=\u001b[39m tqdm(\u001b[38;5;28mrange\u001b[39m(num_self_play),\n\u001b[1;32m    294\u001b[0m                     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpisode \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepisode\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_episodes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    295\u001b[0m                     position\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m self_play_bar:\n\u001b[0;32m--> 298\u001b[0m     data, reward \u001b[38;5;241m=\u001b[39m self_play_episode(make_env\u001b[38;5;241m=\u001b[39mmake_env,\n\u001b[1;32m    299\u001b[0m                                     net\u001b[38;5;241m=\u001b[39mnet,\n\u001b[1;32m    300\u001b[0m                                     num_sims\u001b[38;5;241m=\u001b[39mnum_sims,\n\u001b[1;32m    301\u001b[0m                                     tau\u001b[38;5;241m=\u001b[39mtau,\n\u001b[1;32m    302\u001b[0m                                     cpuct\u001b[38;5;241m=\u001b[39mcpuct,\n\u001b[1;32m    303\u001b[0m                                     device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m    304\u001b[0m                                     verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m state, pi \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;66;03m# Convert state to one-hot encoding\u001b[39;00m\n\u001b[1;32m    308\u001b[0m         replay_buffer\u001b[38;5;241m.\u001b[39madd(state\u001b[38;5;241m=\u001b[39mstate,\n\u001b[1;32m    309\u001b[0m                         mcts_policy\u001b[38;5;241m=\u001b[39mpi,\n\u001b[1;32m    310\u001b[0m                         value\u001b[38;5;241m=\u001b[39mreward)\n",
            "File \u001b[0;32m~/Desktop/UoEYear5/laas/monte-carlo-manipulation/src/train.py:111\u001b[0m, in \u001b[0;36mself_play_episode\u001b[0;34m(make_env, net, num_sims, tau, cpuct, device, verbose)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[1;32m    104\u001b[0m     root_node \u001b[38;5;241m=\u001b[39m LearnedMCTSNode(state\u001b[38;5;241m=\u001b[39mstate,\n\u001b[1;32m    105\u001b[0m                                 make_env\u001b[38;5;241m=\u001b[39mmake_env,\n\u001b[1;32m    106\u001b[0m                                 net\u001b[38;5;241m=\u001b[39mnet,\n\u001b[1;32m    107\u001b[0m                                 cpuct\u001b[38;5;241m=\u001b[39mcpuct,\n\u001b[1;32m    108\u001b[0m                                 device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m    109\u001b[0m                                 verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[0;32m--> 111\u001b[0m     pi \u001b[38;5;241m=\u001b[39m run_mcts(root_node, tau\u001b[38;5;241m=\u001b[39mtau, num_sims\u001b[38;5;241m=\u001b[39mnum_sims)\n\u001b[1;32m    113\u001b[0m     action \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(pi)), p\u001b[38;5;241m=\u001b[39mpi)\n\u001b[1;32m    115\u001b[0m     next_state, reward, terminated, truncated, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n",
            "File \u001b[0;32m~/Desktop/UoEYear5/laas/monte-carlo-manipulation/src/train.py:73\u001b[0m, in \u001b[0;36mrun_mcts\u001b[0;34m(root_node, tau, num_sims, pipeline_verbose)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBACKPROPAGATING REWARD: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from terminal node \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 73\u001b[0m     value \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mevaluation() \u001b[38;5;66;03m# get value from NN\u001b[39;00m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pipeline_verbose:\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBACKPROPAGATING VALUE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from non-terminal node \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/Desktop/UoEYear5/laas/monte-carlo-manipulation/src/mcts_models.py:290\u001b[0m, in \u001b[0;36mLearnedMCTSNode.evaluation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    288\u001b[0m s_tensor \u001b[38;5;241m=\u001b[39m to_one_hot_encoding(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mobservation_space)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 290\u001b[0m     _, value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet(s_tensor\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m value\u001b[38;5;241m.\u001b[39mitem()\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/Desktop/UoEYear5/laas/monte-carlo-manipulation/src/mcts_models.py:150\u001b[0m, in \u001b[0;36mAlphaZeroNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;66;03m# x: one-hot or feature vector of shape (batch, n_states)\u001b[39;00m\n\u001b[1;32m    149\u001b[0m     h \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(x))\n\u001b[0;32m--> 150\u001b[0m     h \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(h))\n\u001b[1;32m    151\u001b[0m     p \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mlog_softmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_head(h), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# log-probs\u001b[39;00m\n\u001b[1;32m    152\u001b[0m     v \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtanh(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue_head(h))             \u001b[38;5;66;03m# in [-1,1]\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train_pipeline(net=net,\n",
        "                make_env=make_env,\n",
        "                optimizer=optimizer,\n",
        "                scheduler=scheduler,\n",
        "                buffer_size=BUFFER_SIZE,\n",
        "                sample_size=SAMPLE_SIZE,\n",
        "                batch_size=BATCH_SIZE,\n",
        "                num_sims=NUM_SIMS,\n",
        "                num_epochs=NUM_EPOCHS,\n",
        "                tau=TAU,\n",
        "                cpuct=CPUCT,\n",
        "                num_episodes=MAX_EPISODES,\n",
        "                num_self_play=NUM_SELF_PLAY,\n",
        "                eval_interval=EVAL_INTERVAL,\n",
        "                num_eval=NUM_EVAL,\n",
        "                target_sr=TARGET_SR,\n",
        "                device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
