{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","mount_file_id":"1poeNGFM_sc4IGEWs302d_iMgKkvBuQjX","authorship_tag":"ABX9TyMoAcu+5HkQzJiuKeC6vRjN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":20,"metadata":{"id":"jiFSwxk5cWTa","executionInfo":{"status":"ok","timestamp":1746992540731,"user_tz":-60,"elapsed":127,"user":{"displayName":"Julia López Gómez","userId":"04858267532126932932"}}},"outputs":[],"source":["import os\n","import gymnasium as gym\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import math\n","import random\n","import copy"]},{"cell_type":"code","source":["###TODO: DELETE THIS FOR FINAL VERSION\n","GITHUB_USER = \"julialopezgomez\"\n","GITHUB_TOKEN = \"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\""],"metadata":{"id":"De0mzFn4eQ47","executionInfo":{"status":"ok","timestamp":1746990428064,"user_tz":-60,"elapsed":6,"user":{"displayName":"Julia López Gómez","userId":"04858267532126932932"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["###TODO: DELETE THIS FOR FINAL VERSION\n","%%bash\n","cat > ~/.netrc <<EOF\n","machine github.com\n","  login julialopezgomez\n","  password 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\n","EOF\n","\n","# Secure it so only you can read it:\n","chmod 600 ~/.netrc\n"],"metadata":{"id":"YL3sMC4ezjv4","executionInfo":{"status":"ok","timestamp":1746991483271,"user_tz":-60,"elapsed":14,"user":{"displayName":"Julia López Gómez","userId":"04858267532126932932"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["%%bash\n","###TODO: DELETE THIS FOR FINAL VERSION\n","# configure git to use your token over HTTPS\n","git config --global user.email \"s2107370@ed.ac.uk\"\n","git config --global user.name  \"julialopezgomez\"\n","###\n","\n","\n","# clone via token\n","git clone https://github.com/julialopezgomez/monte-carlo-manipulation.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dRxMk0yTfIgp","executionInfo":{"status":"ok","timestamp":1746990296392,"user_tz":-60,"elapsed":2849,"user":{"displayName":"Julia López Gómez","userId":"04858267532126932932"}},"outputId":"a4baeca3-e2c7-43c9-d2c7-68d5a95f2000"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["Cloning into 'monte-carlo-manipulation'...\n"]}]},{"cell_type":"code","source":["%%bash\n","cd monte-carlo-manipulation\n","pip install --upgrade pip\n","pip instal  l -r src/requirements.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qWOo5C-xfq_V","executionInfo":{"status":"ok","timestamp":1746991322161,"user_tz":-60,"elapsed":15480,"user":{"displayName":"Julia López Gómez","userId":"04858267532126932932"}},"outputId":"7027bb2f-1eff-41f7-e93e-7f28d3d93f71"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (25.1.1)\n","Collecting torch@ https://download.pytorch.org/whl/cu117/torch-2.0.1%2Bcu117-cp311-cp311-linux_x86_64.whl (from -r src/requirements.txt (line 2))\n","  Using cached https://download.pytorch.org/whl/cu117/torch-2.0.1%2Bcu117-cp311-cp311-linux_x86_64.whl (1843.9 MB)\n","Collecting torchvision@ https://download.pytorch.org/whl/cu117/torchvision-0.15.2%2Bcu117-cp311-cp311-linux_x86_64.whl (from -r src/requirements.txt (line 3))\n","  Using cached https://download.pytorch.org/whl/cu117/torchvision-0.15.2%2Bcu117-cp311-cp311-linux_x86_64.whl (6.1 MB)\n","Requirement already satisfied: torchaudio==2.0.2 in /usr/local/lib/python3.11/dist-packages (from -r src/requirements.txt (line 4)) (2.0.2)\n","Requirement already satisfied: ipywidgets==8.0.4 in /usr/local/lib/python3.11/dist-packages (from -r src/requirements.txt (line 7)) (8.0.4)\n","Requirement already satisfied: widgetsnbextension==4.0.5 in /usr/local/lib/python3.11/dist-packages (from -r src/requirements.txt (line 8)) (4.0.5)\n","Requirement already satisfied: jupyterlab-widgets in /usr/local/lib/python3.11/dist-packages (from -r src/requirements.txt (line 9)) (3.0.14)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r src/requirements.txt (line 12)) (1.26.4)\n","Collecting scipy<2.0.0,>=1.11.4 (from -r src/requirements.txt (line 13))\n","  Downloading scipy-1.15.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n","Requirement already satisfied: pymcubes==0.1.4 in /usr/local/lib/python3.11/dist-packages (from -r src/requirements.txt (line 14)) (0.1.4)\n","Requirement already satisfied: quadprog in /usr/local/lib/python3.11/dist-packages (from -r src/requirements.txt (line 15)) (0.1.13)\n","Requirement already satisfied: cvxpy in /usr/local/lib/python3.11/dist-packages (from -r src/requirements.txt (line 18)) (1.6.0)\n","Requirement already satisfied: mosek in /usr/local/lib/python3.11/dist-packages (from -r src/requirements.txt (line 19)) (11.0.20)\n","Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from -r src/requirements.txt (line 23)) (5.24.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r src/requirements.txt (line 24)) (4.67.1)\n","Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (from -r src/requirements.txt (line 25)) (0.19.10)\n","Requirement already satisfied: gymnasium in /usr/local/lib/python3.11/dist-packages (from -r src/requirements.txt (line 28)) (1.1.1)\n","Requirement already satisfied: gurobipy in /usr/local/lib/python3.11/dist-packages (from -r src/requirements.txt (line 29)) (12.0.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch@ https://download.pytorch.org/whl/cu117/torch-2.0.1%2Bcu117-cp311-cp311-linux_x86_64.whl->-r src/requirements.txt (line 2)) (3.18.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch@ https://download.pytorch.org/whl/cu117/torch-2.0.1%2Bcu117-cp311-cp311-linux_x86_64.whl->-r src/requirements.txt (line 2)) (4.13.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch@ https://download.pytorch.org/whl/cu117/torch-2.0.1%2Bcu117-cp311-cp311-linux_x86_64.whl->-r src/requirements.txt (line 2)) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch@ https://download.pytorch.org/whl/cu117/torch-2.0.1%2Bcu117-cp311-cp311-linux_x86_64.whl->-r src/requirements.txt (line 2)) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch@ https://download.pytorch.org/whl/cu117/torch-2.0.1%2Bcu117-cp311-cp311-linux_x86_64.whl->-r src/requirements.txt (line 2)) (3.1.6)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch@ https://download.pytorch.org/whl/cu117/torch-2.0.1%2Bcu117-cp311-cp311-linux_x86_64.whl->-r src/requirements.txt (line 2)) (2.0.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision@ https://download.pytorch.org/whl/cu117/torchvision-0.15.2%2Bcu117-cp311-cp311-linux_x86_64.whl->-r src/requirements.txt (line 3)) (2.32.3)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision@ https://download.pytorch.org/whl/cu117/torchvision-0.15.2%2Bcu117-cp311-cp311-linux_x86_64.whl->-r src/requirements.txt (line 3)) (11.2.1)\n","Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets==8.0.4->-r src/requirements.txt (line 7)) (6.17.1)\n","Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets==8.0.4->-r src/requirements.txt (line 7)) (7.34.0)\n","Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets==8.0.4->-r src/requirements.txt (line 7)) (5.7.1)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch@ https://download.pytorch.org/whl/cu117/torch-2.0.1%2Bcu117-cp311-cp311-linux_x86_64.whl->-r src/requirements.txt (line 2)) (3.31.6)\n","Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch@ https://download.pytorch.org/whl/cu117/torch-2.0.1%2Bcu117-cp311-cp311-linux_x86_64.whl->-r src/requirements.txt (line 2)) (18.1.8)\n","Requirement already satisfied: osqp>=0.6.2 in /usr/local/lib/python3.11/dist-packages (from cvxpy->-r src/requirements.txt (line 18)) (1.0.3)\n","Requirement already satisfied: clarabel>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from cvxpy->-r src/requirements.txt (line 18)) (0.10.0)\n","Requirement already satisfied: scs>=3.2.4.post1 in /usr/local/lib/python3.11/dist-packages (from cvxpy->-r src/requirements.txt (line 18)) (3.2.7.post2)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->-r src/requirements.txt (line 23)) (9.1.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from plotly->-r src/requirements.txt (line 23)) (24.2)\n","Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb->-r src/requirements.txt (line 25)) (8.1.8)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r src/requirements.txt (line 25)) (0.4.0)\n","Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r src/requirements.txt (line 25)) (3.1.44)\n","Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb->-r src/requirements.txt (line 25)) (4.3.7)\n","Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r src/requirements.txt (line 25)) (5.29.4)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r src/requirements.txt (line 25)) (5.9.5)\n","Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb->-r src/requirements.txt (line 25)) (2.11.4)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb->-r src/requirements.txt (line 25)) (6.0.2)\n","Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r src/requirements.txt (line 25)) (2.27.0)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb->-r src/requirements.txt (line 25)) (1.3.6)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb->-r src/requirements.txt (line 25)) (75.2.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb->-r src/requirements.txt (line 25)) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb->-r src/requirements.txt (line 25)) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb->-r src/requirements.txt (line 25)) (0.4.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision@ https://download.pytorch.org/whl/cu117/torchvision-0.15.2%2Bcu117-cp311-cp311-linux_x86_64.whl->-r src/requirements.txt (line 3)) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision@ https://download.pytorch.org/whl/cu117/torchvision-0.15.2%2Bcu117-cp311-cp311-linux_x86_64.whl->-r src/requirements.txt (line 3)) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision@ https://download.pytorch.org/whl/cu117/torchvision-0.15.2%2Bcu117-cp311-cp311-linux_x86_64.whl->-r src/requirements.txt (line 3)) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision@ https://download.pytorch.org/whl/cu117/torchvision-0.15.2%2Bcu117-cp311-cp311-linux_x86_64.whl->-r src/requirements.txt (line 3)) (2025.4.26)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium->-r src/requirements.txt (line 28)) (3.1.1)\n","Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium->-r src/requirements.txt (line 28)) (0.0.4)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb->-r src/requirements.txt (line 25)) (1.17.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->-r src/requirements.txt (line 25)) (4.0.12)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r src/requirements.txt (line 25)) (5.0.2)\n","Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets==8.0.4->-r src/requirements.txt (line 7)) (1.8.0)\n","Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets==8.0.4->-r src/requirements.txt (line 7)) (6.1.12)\n","Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets==8.0.4->-r src/requirements.txt (line 7)) (0.1.7)\n","Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets==8.0.4->-r src/requirements.txt (line 7)) (1.6.0)\n","Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets==8.0.4->-r src/requirements.txt (line 7)) (24.0.1)\n","Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets==8.0.4->-r src/requirements.txt (line 7)) (6.4.2)\n","Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets==8.0.4->-r src/requirements.txt (line 7)) (0.19.2)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets==8.0.4->-r src/requirements.txt (line 7)) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets==8.0.4->-r src/requirements.txt (line 7)) (0.7.5)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets==8.0.4->-r src/requirements.txt (line 7)) (3.0.51)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets==8.0.4->-r src/requirements.txt (line 7)) (2.19.1)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets==8.0.4->-r src/requirements.txt (line 7)) (0.2.0)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets==8.0.4->-r src/requirements.txt (line 7)) (4.9.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets==8.0.4->-r src/requirements.txt (line 7)) (0.2.13)\n","Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets==8.0.4->-r src/requirements.txt (line 7)) (0.8.4)\n","Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets==8.0.4->-r src/requirements.txt (line 7)) (5.7.2)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets==8.0.4->-r src/requirements.txt (line 7)) (2.9.0.post0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from osqp>=0.6.2->cvxpy->-r src/requirements.txt (line 18)) (1.4.2)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets==8.0.4->-r src/requirements.txt (line 7)) (0.7.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch@ https://download.pytorch.org/whl/cu117/torch-2.0.1%2Bcu117-cp311-cp311-linux_x86_64.whl->-r src/requirements.txt (line 2)) (3.0.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch@ https://download.pytorch.org/whl/cu117/torch-2.0.1%2Bcu117-cp311-cp311-linux_x86_64.whl->-r src/requirements.txt (line 2)) (1.3.0)\n","Downloading scipy-1.15.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 37.7/37.7 MB 130.0 MB/s eta 0:00:00\n","Installing collected packages: scipy\n","  Attempting uninstall: scipy\n","    Found existing installation: scipy 1.10.1\n","    Uninstalling scipy-1.10.1:\n","      Successfully uninstalled scipy-1.10.1\n","Successfully installed scipy-1.15.3\n"]}]},{"cell_type":"code","source":["# --- MCTS Node Class ---\n","class MCTSNode:\n","    def __init__(self, state, parent=None, action=None, make_env=None, verbose=False):\n","        self.state = state\n","        self.parent = parent\n","        self.action = action\n","        self.children = []\n","        self.visits = 0\n","        self.value = 0.0\n","        self.make_env = make_env\n","        self.verbose = verbose\n","\n","    def is_leaf(self):\n","        return len(self.children) == 0\n","\n","    def uct(self, exploration=1.41):\n","        if self.visits == 0 or self.parent is None:\n","            return float(\"inf\")\n","        exploitation = self.value / self.visits\n","        exploration_bonus = exploration * math.sqrt(math.log(self.parent.visits) / self.visits)\n","        return exploitation + exploration_bonus\n","\n","    def best_uct_child(self):\n","        return max(self.children, key=lambda child: child.uct())\n","\n","    def best_child(self):\n","        return max(self.children, key=lambda child: child.value)\n","\n","    def selection(self, env):\n","        \"\"\"Traverse the tree to select a promising node to expand.\"\"\"\n","        node = self\n","        while not node.is_leaf():\n","            node = node.best_uct_child()\n","        if node.visits == 0:\n","            return node, None\n","        goal_node = node.expand(env)\n","        return (goal_node if goal_node else random.choice(node.children), goal_node is not None)\n","\n","    def expand(self, env):\n","        \"\"\"Expand the node by trying all possible actions.\"\"\"\n","        for action in range(env.action_space.n):\n","            env_copy = self.make_env()\n","            env_copy.reset()\n","            env_copy.unwrapped.s = self.state\n","            obs, reward, terminated, truncated, _ = env_copy.step(action)\n","\n","            # Only add child if it is not a (non successful) terminal state or if it is not the same state\n","            if reward == 0 and terminated or self.state == obs:\n","                continue\n","\n","            child = MCTSNode(obs, parent=self, action=action, make_env=self.make_env, verbose=self.verbose)\n","            self.children.append(child)\n","\n","            if reward == 1:\n","                if self.verbose:\n","                    print(f\"Goal found from state {self.state} with action {action} → {obs}\")\n","                return child\n","\n","        if self.verbose:\n","            print(f\"Expanded node {self.state} with children: {[c.state for c in self.children]}\")\n","        return None\n","\n","    def simulation(self, max_steps=10):\n","        \"\"\"Perform a rollout from the current node using random actions.\"\"\"\n","        env_copy = self.make_env()\n","        env_copy.reset()\n","        env_copy.unwrapped.s = self.state\n","        obs = self.state\n","\n","        for _ in range(max_steps):\n","            action = env_copy.action_space.sample()\n","            obs, reward, terminated, truncated, _ = env_copy.step(action)\n","\n","            if self.verbose:\n","                print(f\"Simulating from {self.state} → {obs} with action {action} reward {reward}\")\n","\n","            if reward == 1 or terminated or truncated:\n","                return reward\n","        return 0\n","\n","    def backpropagation(self, reward):\n","        \"\"\"Propagate the simulation result back up the tree.\"\"\"\n","        node = self\n","        while node:\n","            node.visits += 1\n","            node.value += reward\n","            if self.verbose:\n","                print(f\"Backprop node {node.state}, visits={node.visits}, value={node.value}\")\n","            node = node.parent\n"],"metadata":{"id":"GgAyOxEWfxTr","executionInfo":{"status":"ok","timestamp":1746992547182,"user_tz":-60,"elapsed":15,"user":{"displayName":"Julia López Gómez","userId":"04858267532126932932"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["\n","# --- MCTS Search Class ---\n","class MCTS:\n","    def __init__(self, make_env, num_iterations=100, num_simulations=10, exploration=1.41, verbose=False):\n","        self.make_env = make_env\n","        self.env = make_env()\n","        self.root = MCTSNode(self.env.reset()[0], make_env=self.make_env, verbose=verbose)\n","        self.num_iterations = num_iterations\n","        self.num_simulations = num_simulations\n","        self.exploration = exploration\n","        self.verbose = verbose\n","        self.root.expand(self.env)\n","\n","    def run(self):\n","        for _ in range(self.num_iterations):\n","            node, goal = self.root.selection(self.env)\n","            if goal:\n","                node.backpropagation(1)\n","                if self.verbose:\n","                    print(f\"Goal reached at state {node.state}\")\n","                break\n","            reward = node.simulation(max_steps=self.num_simulations)\n","            node.backpropagation(reward)\n","        if self.verbose:\n","            print(f\"Finished {self.num_iterations} iterations.\")"],"metadata":{"id":"EJT1sqoV3Wkb","executionInfo":{"status":"ok","timestamp":1746992547431,"user_tz":-60,"elapsed":2,"user":{"displayName":"Julia López Gómez","userId":"04858267532126932932"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["\n","# --- Main Execution ---\n","def make_env():\n","    return gym.make(\"FrozenLake-v1\", is_slippery=False, render_mode=\"ansi\")\n","\n","# Run MCTS\n","mcts = MCTS(make_env=make_env, num_iterations=1000, num_simulations=100, exploration=1.41, verbose=True)\n","mcts.run()\n","\n","# Visualise best path\n","env = make_env()\n","env.reset()\n","print(\"Initial state:\")\n","print(env.render())\n","\n","trajectory = []\n","node = mcts.root\n","trajectory.append((node.state, node.action, node.value))\n","while not node.is_leaf():\n","    prev_node = node\n","    node = prev_node.best_child()\n","    trajectory.append((node.state, node.action, node.value))\n","    print(f\"Best action from state {prev_node.state} to state {node.state} with value {node.value}\")\n","    env.step(node.action)\n","    print(env.render())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QfLn8zLC3d0J","executionInfo":{"status":"ok","timestamp":1746992560489,"user_tz":-60,"elapsed":18,"user":{"displayName":"Julia López Gómez","userId":"04858267532126932932"}},"outputId":"87022334-ca52-4675-ff2f-e230aa17a08f"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Expanded node 0 with children: [4, 1]\n","Simulating from 4 → 5 with action 2 reward 0.0\n","Backprop node 4, visits=1, value=0.0\n","Backprop node 0, visits=1, value=0.0\n","Simulating from 1 → 0 with action 0 reward 0.0\n","Simulating from 1 → 4 with action 1 reward 0.0\n","Simulating from 1 → 4 with action 0 reward 0.0\n","Simulating from 1 → 8 with action 1 reward 0.0\n","Simulating from 1 → 12 with action 1 reward 0.0\n","Backprop node 1, visits=1, value=0.0\n","Backprop node 0, visits=2, value=0.0\n","Expanded node 4 with children: [8, 0]\n","Simulating from 8 → 9 with action 2 reward 0.0\n","Simulating from 8 → 10 with action 2 reward 0.0\n","Simulating from 8 → 14 with action 1 reward 0.0\n","Simulating from 8 → 15 with action 2 reward 1.0\n","Backprop node 8, visits=1, value=1.0\n","Backprop node 4, visits=2, value=1.0\n","Backprop node 0, visits=3, value=1.0\n","Simulating from 0 → 0 with action 3 reward 0.0\n","Simulating from 0 → 0 with action 0 reward 0.0\n","Simulating from 0 → 1 with action 2 reward 0.0\n","Simulating from 0 → 1 with action 3 reward 0.0\n","Simulating from 0 → 1 with action 3 reward 0.0\n","Simulating from 0 → 1 with action 3 reward 0.0\n","Simulating from 0 → 0 with action 0 reward 0.0\n","Simulating from 0 → 1 with action 2 reward 0.0\n","Simulating from 0 → 1 with action 3 reward 0.0\n","Simulating from 0 → 5 with action 1 reward 0.0\n","Backprop node 0, visits=1, value=0.0\n","Backprop node 4, visits=3, value=1.0\n","Backprop node 0, visits=4, value=1.0\n","Expanded node 1 with children: [0, 2]\n","Simulating from 2 → 1 with action 0 reward 0.0\n","Simulating from 2 → 5 with action 1 reward 0.0\n","Backprop node 2, visits=1, value=0.0\n","Backprop node 1, visits=2, value=0.0\n","Backprop node 0, visits=5, value=1.0\n","Expanded node 8 with children: [9, 4]\n","Simulating from 4 → 0 with action 3 reward 0.0\n","Simulating from 4 → 4 with action 1 reward 0.0\n","Simulating from 4 → 4 with action 0 reward 0.0\n","Simulating from 4 → 8 with action 1 reward 0.0\n","Simulating from 4 → 8 with action 0 reward 0.0\n","Simulating from 4 → 12 with action 1 reward 0.0\n","Backprop node 4, visits=1, value=0.0\n","Backprop node 8, visits=2, value=1.0\n","Backprop node 4, visits=4, value=1.0\n","Backprop node 0, visits=6, value=1.0\n","Simulating from 0 → 1 with action 2 reward 0.0\n","Simulating from 0 → 5 with action 1 reward 0.0\n","Backprop node 0, visits=1, value=0.0\n","Backprop node 1, visits=3, value=0.0\n","Backprop node 0, visits=7, value=1.0\n","Simulating from 9 → 8 with action 0 reward 0.0\n","Simulating from 9 → 4 with action 3 reward 0.0\n","Simulating from 9 → 4 with action 0 reward 0.0\n","Simulating from 9 → 8 with action 1 reward 0.0\n","Simulating from 9 → 4 with action 3 reward 0.0\n","Simulating from 9 → 5 with action 2 reward 0.0\n","Backprop node 9, visits=1, value=0.0\n","Backprop node 8, visits=3, value=1.0\n","Backprop node 4, visits=5, value=1.0\n","Backprop node 0, visits=8, value=1.0\n","Expanded node 0 with children: [4, 1]\n","Simulating from 1 → 5 with action 1 reward 0.0\n","Backprop node 1, visits=1, value=0.0\n","Backprop node 0, visits=2, value=0.0\n","Backprop node 1, visits=4, value=0.0\n","Backprop node 0, visits=9, value=1.0\n","Expanded node 0 with children: [4, 1]\n","Simulating from 4 → 5 with action 2 reward 0.0\n","Backprop node 4, visits=1, value=0.0\n","Backprop node 0, visits=2, value=0.0\n","Backprop node 4, visits=6, value=1.0\n","Backprop node 0, visits=10, value=1.0\n","Expanded node 2 with children: [1, 6, 3]\n","Simulating from 1 → 5 with action 1 reward 0.0\n","Backprop node 1, visits=1, value=0.0\n","Backprop node 2, visits=2, value=0.0\n","Backprop node 1, visits=5, value=0.0\n","Backprop node 0, visits=11, value=1.0\n","Expanded node 9 with children: [8, 13, 10]\n","Simulating from 8 → 9 with action 2 reward 0.0\n","Simulating from 8 → 13 with action 1 reward 0.0\n","Simulating from 8 → 13 with action 1 reward 0.0\n","Simulating from 8 → 14 with action 2 reward 0.0\n","Simulating from 8 → 15 with action 2 reward 1.0\n","Backprop node 8, visits=1, value=1.0\n","Backprop node 9, visits=2, value=1.0\n","Backprop node 8, visits=4, value=2.0\n","Backprop node 4, visits=7, value=2.0\n","Backprop node 0, visits=12, value=2.0\n","Simulating from 13 → 13 with action 1 reward 0.0\n","Simulating from 13 → 14 with action 2 reward 0.0\n","Simulating from 13 → 15 with action 2 reward 1.0\n","Backprop node 13, visits=1, value=1.0\n","Backprop node 9, visits=3, value=2.0\n","Backprop node 8, visits=5, value=3.0\n","Backprop node 4, visits=8, value=3.0\n","Backprop node 0, visits=13, value=3.0\n","Expanded node 4 with children: [8, 0]\n","Simulating from 0 → 4 with action 1 reward 0.0\n","Simulating from 0 → 0 with action 3 reward 0.0\n","Simulating from 0 → 0 with action 3 reward 0.0\n","Simulating from 0 → 4 with action 1 reward 0.0\n","Simulating from 0 → 4 with action 0 reward 0.0\n","Simulating from 0 → 5 with action 2 reward 0.0\n","Backprop node 0, visits=1, value=0.0\n","Backprop node 4, visits=2, value=0.0\n","Backprop node 8, visits=6, value=3.0\n","Backprop node 4, visits=9, value=3.0\n","Backprop node 0, visits=14, value=3.0\n","Simulating from 1 → 1 with action 3 reward 0.0\n","Simulating from 1 → 1 with action 3 reward 0.0\n","Simulating from 1 → 1 with action 3 reward 0.0\n","Simulating from 1 → 1 with action 3 reward 0.0\n","Simulating from 1 → 1 with action 3 reward 0.0\n","Simulating from 1 → 1 with action 3 reward 0.0\n","Simulating from 1 → 1 with action 3 reward 0.0\n","Simulating from 1 → 5 with action 1 reward 0.0\n","Backprop node 1, visits=1, value=0.0\n","Backprop node 0, visits=3, value=0.0\n","Backprop node 4, visits=10, value=3.0\n","Backprop node 0, visits=15, value=3.0\n","Simulating from 4 → 5 with action 2 reward 0.0\n","Backprop node 4, visits=1, value=0.0\n","Backprop node 0, visits=3, value=0.0\n","Backprop node 1, visits=6, value=0.0\n","Backprop node 0, visits=16, value=3.0\n","Simulating from 10 → 14 with action 1 reward 0.0\n","Simulating from 10 → 13 with action 0 reward 0.0\n","Simulating from 10 → 9 with action 3 reward 0.0\n","Simulating from 10 → 10 with action 2 reward 0.0\n","Simulating from 10 → 6 with action 3 reward 0.0\n","Simulating from 10 → 5 with action 0 reward 0.0\n","Backprop node 10, visits=1, value=0.0\n","Backprop node 9, visits=4, value=2.0\n","Backprop node 8, visits=7, value=3.0\n","Backprop node 4, visits=11, value=3.0\n","Backprop node 0, visits=17, value=3.0\n","Expanded node 4 with children: [8, 0]\n","Simulating from 8 → 8 with action 0 reward 0.0\n","Simulating from 8 → 8 with action 0 reward 0.0\n","Simulating from 8 → 4 with action 3 reward 0.0\n","Simulating from 8 → 0 with action 3 reward 0.0\n","Simulating from 8 → 4 with action 1 reward 0.0\n","Simulating from 8 → 4 with action 0 reward 0.0\n","Simulating from 8 → 8 with action 1 reward 0.0\n","Simulating from 8 → 8 with action 0 reward 0.0\n","Simulating from 8 → 8 with action 0 reward 0.0\n","Simulating from 8 → 9 with action 2 reward 0.0\n","Simulating from 8 → 8 with action 0 reward 0.0\n","Simulating from 8 → 9 with action 2 reward 0.0\n","Simulating from 8 → 8 with action 0 reward 0.0\n","Simulating from 8 → 8 with action 0 reward 0.0\n","Simulating from 8 → 12 with action 1 reward 0.0\n","Backprop node 8, visits=1, value=0.0\n","Backprop node 4, visits=2, value=0.0\n","Backprop node 0, visits=4, value=0.0\n","Backprop node 4, visits=12, value=3.0\n","Backprop node 0, visits=18, value=3.0\n","Simulating from 6 → 2 with action 3 reward 0.0\n","Simulating from 6 → 2 with action 3 reward 0.0\n","Simulating from 6 → 2 with action 3 reward 0.0\n","Simulating from 6 → 3 with action 2 reward 0.0\n","Simulating from 6 → 3 with action 3 reward 0.0\n","Simulating from 6 → 2 with action 0 reward 0.0\n","Simulating from 6 → 6 with action 1 reward 0.0\n","Simulating from 6 → 7 with action 2 reward 0.0\n","Backprop node 6, visits=1, value=0.0\n","Backprop node 2, visits=3, value=0.0\n","Backprop node 1, visits=7, value=0.0\n","Backprop node 0, visits=19, value=3.0\n","Expanded node 8 with children: [9, 4]\n","Simulating from 9 → 13 with action 1 reward 0.0\n","Simulating from 9 → 9 with action 3 reward 0.0\n","Simulating from 9 → 10 with action 2 reward 0.0\n","Simulating from 9 → 6 with action 3 reward 0.0\n","Simulating from 9 → 2 with action 3 reward 0.0\n","Simulating from 9 → 1 with action 0 reward 0.0\n","Simulating from 9 → 5 with action 1 reward 0.0\n","Backprop node 9, visits=1, value=0.0\n","Backprop node 8, visits=2, value=1.0\n","Backprop node 9, visits=5, value=2.0\n","Backprop node 8, visits=8, value=3.0\n","Backprop node 4, visits=13, value=3.0\n","Backprop node 0, visits=20, value=3.0\n","Expanded node 4 with children: [8, 0]\n","Simulating from 0 → 4 with action 1 reward 0.0\n","Simulating from 0 → 5 with action 2 reward 0.0\n","Backprop node 0, visits=1, value=0.0\n","Backprop node 4, visits=2, value=0.0\n","Backprop node 0, visits=4, value=0.0\n","Backprop node 1, visits=8, value=0.0\n","Backprop node 0, visits=21, value=3.0\n","Simulating from 8 → 8 with action 0 reward 0.0\n","Simulating from 8 → 9 with action 2 reward 0.0\n","Simulating from 8 → 5 with action 3 reward 0.0\n","Backprop node 8, visits=1, value=0.0\n","Backprop node 4, visits=3, value=0.0\n","Backprop node 8, visits=9, value=3.0\n","Backprop node 4, visits=14, value=3.0\n","Backprop node 0, visits=22, value=3.0\n","Expanded node 1 with children: [0, 2]\n","Simulating from 0 → 0 with action 3 reward 0.0\n","Simulating from 0 → 0 with action 3 reward 0.0\n","Simulating from 0 → 1 with action 2 reward 0.0\n","Simulating from 0 → 0 with action 0 reward 0.0\n","Simulating from 0 → 0 with action 0 reward 0.0\n","Simulating from 0 → 1 with action 2 reward 0.0\n","Simulating from 0 → 0 with action 0 reward 0.0\n","Simulating from 0 → 4 with action 1 reward 0.0\n","Simulating from 0 → 5 with action 2 reward 0.0\n","Backprop node 0, visits=1, value=0.0\n","Backprop node 1, visits=2, value=0.0\n","Backprop node 0, visits=5, value=0.0\n","Backprop node 4, visits=15, value=3.0\n","Backprop node 0, visits=23, value=3.0\n","Simulating from 3 → 3 with action 2 reward 0.0\n","Simulating from 3 → 3 with action 3 reward 0.0\n","Simulating from 3 → 7 with action 1 reward 0.0\n","Backprop node 3, visits=1, value=0.0\n","Backprop node 2, visits=4, value=0.0\n","Backprop node 1, visits=9, value=0.0\n","Backprop node 0, visits=24, value=3.0\n","Expanded node 13 with children: [14, 9]\n","Simulating from 14 → 15 with action 2 reward 1.0\n","Backprop node 14, visits=1, value=1.0\n","Backprop node 13, visits=2, value=2.0\n","Backprop node 9, visits=6, value=3.0\n","Backprop node 8, visits=10, value=4.0\n","Backprop node 4, visits=16, value=4.0\n","Backprop node 0, visits=25, value=4.0\n","Simulating from 9 → 5 with action 3 reward 0.0\n","Backprop node 9, visits=1, value=0.0\n","Backprop node 13, visits=3, value=2.0\n","Backprop node 9, visits=7, value=3.0\n","Backprop node 8, visits=11, value=4.0\n","Backprop node 4, visits=17, value=4.0\n","Backprop node 0, visits=26, value=4.0\n","Expanded node 8 with children: [9, 4]\n","Simulating from 4 → 5 with action 2 reward 0.0\n","Backprop node 4, visits=1, value=0.0\n","Backprop node 8, visits=2, value=0.0\n","Backprop node 4, visits=4, value=0.0\n","Backprop node 8, visits=12, value=4.0\n","Backprop node 4, visits=18, value=4.0\n","Backprop node 0, visits=27, value=4.0\n","Expanded node 1 with children: [0, 2]\n","Simulating from 0 → 1 with action 2 reward 0.0\n","Simulating from 0 → 2 with action 2 reward 0.0\n","Simulating from 0 → 3 with action 2 reward 0.0\n","Simulating from 0 → 3 with action 3 reward 0.0\n","Simulating from 0 → 3 with action 2 reward 0.0\n","Simulating from 0 → 3 with action 2 reward 0.0\n","Simulating from 0 → 7 with action 1 reward 0.0\n","Backprop node 0, visits=1, value=0.0\n","Backprop node 1, visits=2, value=0.0\n","Backprop node 0, visits=5, value=0.0\n","Backprop node 1, visits=10, value=0.0\n","Backprop node 0, visits=28, value=4.0\n","Simulating from 0 → 4 with action 1 reward 0.0\n","Simulating from 0 → 8 with action 1 reward 0.0\n","Simulating from 0 → 8 with action 0 reward 0.0\n","Simulating from 0 → 9 with action 2 reward 0.0\n","Simulating from 0 → 13 with action 1 reward 0.0\n","Simulating from 0 → 9 with action 3 reward 0.0\n","Simulating from 0 → 13 with action 1 reward 0.0\n","Simulating from 0 → 13 with action 1 reward 0.0\n","Simulating from 0 → 12 with action 0 reward 0.0\n","Backprop node 0, visits=1, value=0.0\n","Backprop node 4, visits=3, value=0.0\n","Backprop node 0, visits=6, value=0.0\n","Backprop node 4, visits=19, value=4.0\n","Backprop node 0, visits=29, value=4.0\n","Expanded node 1 with children: [0, 2]\n","Simulating from 2 → 3 with action 2 reward 0.0\n","Simulating from 2 → 2 with action 0 reward 0.0\n","Simulating from 2 → 1 with action 0 reward 0.0\n","Simulating from 2 → 2 with action 2 reward 0.0\n","Simulating from 2 → 3 with action 2 reward 0.0\n","Simulating from 2 → 3 with action 2 reward 0.0\n","Simulating from 2 → 3 with action 2 reward 0.0\n","Simulating from 2 → 3 with action 2 reward 0.0\n","Simulating from 2 → 3 with action 2 reward 0.0\n","Simulating from 2 → 3 with action 2 reward 0.0\n","Simulating from 2 → 2 with action 0 reward 0.0\n","Simulating from 2 → 3 with action 2 reward 0.0\n","Simulating from 2 → 7 with action 1 reward 0.0\n","Backprop node 2, visits=1, value=0.0\n","Backprop node 1, visits=2, value=0.0\n","Backprop node 2, visits=5, value=0.0\n","Backprop node 1, visits=11, value=0.0\n","Backprop node 0, visits=30, value=4.0\n","Expanded node 10 with children: [9, 14, 6]\n","Simulating from 6 → 7 with action 2 reward 0.0\n","Backprop node 6, visits=1, value=0.0\n","Backprop node 10, visits=2, value=0.0\n","Backprop node 9, visits=8, value=3.0\n","Backprop node 8, visits=13, value=4.0\n","Backprop node 4, visits=20, value=4.0\n","Backprop node 0, visits=31, value=4.0\n","Simulating from 8 → 8 with action 0 reward 0.0\n","Simulating from 8 → 4 with action 3 reward 0.0\n","Simulating from 8 → 0 with action 3 reward 0.0\n","Simulating from 8 → 4 with action 1 reward 0.0\n","Simulating from 8 → 5 with action 2 reward 0.0\n","Backprop node 8, visits=1, value=0.0\n","Backprop node 4, visits=3, value=0.0\n","Backprop node 0, visits=6, value=0.0\n","Backprop node 1, visits=12, value=0.0\n","Backprop node 0, visits=32, value=4.0\n","Simulating from 2 → 6 with action 1 reward 0.0\n","Simulating from 2 → 7 with action 2 reward 0.0\n","Backprop node 2, visits=1, value=0.0\n","Backprop node 1, visits=3, value=0.0\n","Backprop node 0, visits=7, value=0.0\n","Backprop node 4, visits=21, value=4.0\n","Backprop node 0, visits=33, value=4.0\n","Simulating from 4 → 8 with action 1 reward 0.0\n","Simulating from 4 → 8 with action 0 reward 0.0\n","Simulating from 4 → 4 with action 3 reward 0.0\n","Simulating from 4 → 4 with action 0 reward 0.0\n","Simulating from 4 → 5 with action 2 reward 0.0\n","Backprop node 4, visits=1, value=0.0\n","Backprop node 8, visits=3, value=1.0\n","Backprop node 9, visits=9, value=3.0\n","Backprop node 8, visits=14, value=4.0\n","Backprop node 4, visits=22, value=4.0\n","Backprop node 0, visits=34, value=4.0\n","Expanded node 6 with children: [10, 2]\n","Simulating from 10 → 14 with action 1 reward 0.0\n","Simulating from 10 → 14 with action 1 reward 0.0\n","Simulating from 10 → 15 with action 2 reward 1.0\n","Backprop node 10, visits=1, value=1.0\n","Backprop node 6, visits=2, value=1.0\n","Backprop node 2, visits=6, value=1.0\n","Backprop node 1, visits=13, value=1.0\n","Backprop node 0, visits=35, value=5.0\n","Expanded node 3 with children: [2]\n","Simulating from 2 → 1 with action 0 reward 0.0\n","Simulating from 2 → 0 with action 0 reward 0.0\n","Simulating from 2 → 0 with action 3 reward 0.0\n","Simulating from 2 → 1 with action 2 reward 0.0\n","Simulating from 2 → 1 with action 3 reward 0.0\n","Simulating from 2 → 2 with action 2 reward 0.0\n","Simulating from 2 → 1 with action 0 reward 0.0\n","Simulating from 2 → 0 with action 0 reward 0.0\n","Simulating from 2 → 0 with action 3 reward 0.0\n","Simulating from 2 → 1 with action 2 reward 0.0\n","Simulating from 2 → 1 with action 3 reward 0.0\n","Simulating from 2 → 5 with action 1 reward 0.0\n","Backprop node 2, visits=1, value=0.0\n","Backprop node 3, visits=2, value=0.0\n","Backprop node 2, visits=7, value=1.0\n","Backprop node 1, visits=14, value=1.0\n","Backprop node 0, visits=36, value=5.0\n","Simulating from 2 → 6 with action 1 reward 0.0\n","Simulating from 2 → 5 with action 0 reward 0.0\n","Backprop node 2, visits=1, value=0.0\n","Backprop node 6, visits=3, value=1.0\n","Backprop node 2, visits=8, value=1.0\n","Backprop node 1, visits=15, value=1.0\n","Backprop node 0, visits=37, value=5.0\n","Simulating from 2 → 2 with action 3 reward 0.0\n","Simulating from 2 → 6 with action 1 reward 0.0\n","Simulating from 2 → 10 with action 1 reward 0.0\n","Simulating from 2 → 6 with action 3 reward 0.0\n","Simulating from 2 → 7 with action 2 reward 0.0\n","Backprop node 2, visits=1, value=0.0\n","Backprop node 1, visits=3, value=0.0\n","Backprop node 0, visits=7, value=0.0\n","Backprop node 1, visits=16, value=1.0\n","Backprop node 0, visits=38, value=5.0\n","Expanded node 0 with children: [4, 1]\n","Simulating from 1 → 5 with action 1 reward 0.0\n","Backprop node 1, visits=1, value=0.0\n","Backprop node 0, visits=2, value=0.0\n","Backprop node 4, visits=5, value=0.0\n","Backprop node 8, visits=15, value=4.0\n","Backprop node 4, visits=23, value=4.0\n","Backprop node 0, visits=39, value=5.0\n","Expanded node 10 with children: [9, 14, 6]\n","Simulating from 6 → 10 with action 1 reward 0.0\n","Simulating from 6 → 6 with action 3 reward 0.0\n","Simulating from 6 → 2 with action 3 reward 0.0\n","Simulating from 6 → 6 with action 1 reward 0.0\n","Simulating from 6 → 10 with action 1 reward 0.0\n","Simulating from 6 → 14 with action 1 reward 0.0\n","Simulating from 6 → 10 with action 3 reward 0.0\n","Simulating from 6 → 11 with action 2 reward 0.0\n","Backprop node 6, visits=1, value=0.0\n","Backprop node 10, visits=2, value=1.0\n","Backprop node 6, visits=4, value=1.0\n","Backprop node 2, visits=9, value=1.0\n","Backprop node 1, visits=17, value=1.0\n","Backprop node 0, visits=40, value=5.0\n","Expanded node 8 with children: [9, 4]\n","Simulating from 9 → 5 with action 3 reward 0.0\n","Backprop node 9, visits=1, value=0.0\n","Backprop node 8, visits=2, value=0.0\n","Backprop node 4, visits=4, value=0.0\n","Backprop node 0, visits=8, value=0.0\n","Backprop node 4, visits=24, value=4.0\n","Backprop node 0, visits=41, value=5.0\n","Goal found from state 14 with action 2 → 15\n","Backprop node 15, visits=1, value=1.0\n","Backprop node 14, visits=2, value=2.0\n","Backprop node 13, visits=4, value=3.0\n","Backprop node 9, visits=10, value=4.0\n","Backprop node 8, visits=16, value=5.0\n","Backprop node 4, visits=25, value=5.0\n","Backprop node 0, visits=42, value=6.0\n","Goal reached at state 15\n","Finished 1000 iterations.\n","Initial state:\n","\n","\u001b[41mS\u001b[0mFFF\n","FHFH\n","FFFH\n","HFFG\n","\n","Best action from state 0 to state 4 with value 5.0\n","  (Down)\n","SFFF\n","\u001b[41mF\u001b[0mHFH\n","FFFH\n","HFFG\n","\n","Best action from state 4 to state 8 with value 5.0\n","  (Down)\n","SFFF\n","FHFH\n","\u001b[41mF\u001b[0mFFH\n","HFFG\n","\n","Best action from state 8 to state 9 with value 4.0\n","  (Right)\n","SFFF\n","FHFH\n","F\u001b[41mF\u001b[0mFH\n","HFFG\n","\n","Best action from state 9 to state 13 with value 3.0\n","  (Down)\n","SFFF\n","FHFH\n","FFFH\n","H\u001b[41mF\u001b[0mFG\n","\n","Best action from state 13 to state 14 with value 2.0\n","  (Right)\n","SFFF\n","FHFH\n","FFFH\n","HF\u001b[41mF\u001b[0mG\n","\n","Best action from state 14 to state 15 with value 1.0\n","  (Right)\n","SFFF\n","FHFH\n","FFFH\n","HFF\u001b[41mG\u001b[0m\n","\n"]}]},{"cell_type":"code","source":["%%bash\n","cd monte-carlo-manipulation/\n","git add .\n","git commit -m \"collab frozenlake\"\n","git push\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b33WuiTw3k1B","executionInfo":{"status":"ok","timestamp":1746992675373,"user_tz":-60,"elapsed":230,"user":{"displayName":"Julia López Gómez","userId":"04858267532126932932"}},"outputId":"96141cd1-8015-4900-cb03-84f098c32fc8"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["On branch main\n","Your branch is up to date with 'origin/main'.\n","\n","nothing to commit, working tree clean\n"]},{"output_type":"stream","name":"stderr","text":["Everything up-to-date\n"]}]},{"cell_type":"code","source":["%%bash\n","cp drive/MyDrive/Universidad/"],"metadata":{"id":"SVkKu70B4CQS"},"execution_count":null,"outputs":[]}]}