{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCTS implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial state:\n",
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "\n",
      "Best action from state 0 to state 4 with value 3.0\n",
      "  (Down)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "\n",
      "Best action from state 4 to state 8 with value 3.0\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "\n",
      "Best action from state 8 to state 9 with value 3.0\n",
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "F\u001b[41mF\u001b[0mFH\n",
      "HFFG\n",
      "\n",
      "Best action from state 9 to state 13 with value 2.0\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "H\u001b[41mF\u001b[0mFG\n",
      "\n",
      "Best action from state 13 to state 14 with value 2.0\n",
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HF\u001b[41mF\u001b[0mG\n",
      "\n",
      "Best action from state 14 to state 15 with value 1.0\n",
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFF\u001b[41mG\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- MCTS Node Class ---\n",
    "class MCTSNode:\n",
    "    def __init__(self, state, parent=None, action=None, make_env=None, verbose=False):\n",
    "        self.state = state\n",
    "        self.parent = parent\n",
    "        self.action = action\n",
    "        self.children = []\n",
    "        self.visits = 0\n",
    "        self.value = 0.0\n",
    "        self.make_env = make_env\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def is_leaf(self):\n",
    "        return len(self.children) == 0\n",
    "\n",
    "    def uct(self, exploration=1.41):\n",
    "        if self.visits == 0 or self.parent is None:\n",
    "            return float(\"inf\")\n",
    "        exploitation = self.value / self.visits\n",
    "        exploration_bonus = exploration * math.sqrt(math.log(self.parent.visits) / self.visits)\n",
    "        return exploitation + exploration_bonus\n",
    "\n",
    "    def best_uct_child(self):\n",
    "        return max(self.children, key=lambda child: child.uct())\n",
    "\n",
    "    def best_child(self):\n",
    "        return max(self.children, key=lambda child: child.value)\n",
    "\n",
    "    def selection(self, env):\n",
    "        \"\"\"Traverse the tree to select a promising node to expand.\"\"\"\n",
    "        node = self\n",
    "        while not node.is_leaf():\n",
    "            node = node.best_uct_child()\n",
    "        if node.visits == 0:\n",
    "            return node, None\n",
    "        goal_node = node.expand(env)\n",
    "        return (goal_node if goal_node else random.choice(node.children), goal_node is not None)\n",
    "\n",
    "    def expand(self, env):\n",
    "        \"\"\"Expand the node by trying all possible actions.\"\"\"\n",
    "        for action in range(env.action_space.n):\n",
    "            env_copy = self.make_env()\n",
    "            env_copy.reset()\n",
    "            env_copy.unwrapped.s = self.state\n",
    "            obs, reward, terminated, truncated, _ = env_copy.step(action)\n",
    "\n",
    "            if reward == 0 and terminated or self.state == obs:\n",
    "                continue\n",
    "\n",
    "            child = MCTSNode(obs, parent=self, action=action, make_env=self.make_env, verbose=self.verbose)\n",
    "            self.children.append(child)\n",
    "\n",
    "            if reward == 1:\n",
    "                if self.verbose:\n",
    "                    print(f\"Goal found from state {self.state} with action {action} → {obs}\")\n",
    "                return child\n",
    "\n",
    "        if self.verbose:\n",
    "            print(f\"Expanded node {self.state} with children: {[c.state for c in self.children]}\")\n",
    "        return None\n",
    "\n",
    "    def simulation(self, max_steps=10):\n",
    "        \"\"\"Perform a rollout from the current node using random actions.\"\"\"\n",
    "        env_copy = self.make_env()\n",
    "        env_copy.reset()\n",
    "        env_copy.unwrapped.s = self.state\n",
    "        obs = self.state\n",
    "\n",
    "        for _ in range(max_steps):\n",
    "            action = env_copy.action_space.sample()\n",
    "            obs, reward, terminated, truncated, _ = env_copy.step(action)\n",
    "\n",
    "            if self.verbose:\n",
    "                print(f\"Simulating from {self.state} → {obs} with action {action} reward {reward}\")\n",
    "\n",
    "            if reward == 1 or terminated or truncated:\n",
    "                return reward\n",
    "        return 0\n",
    "\n",
    "    def backpropagation(self, reward):\n",
    "        \"\"\"Propagate the simulation result back up the tree.\"\"\"\n",
    "        node = self\n",
    "        while node:\n",
    "            node.visits += 1\n",
    "            node.value += reward\n",
    "            if self.verbose:\n",
    "                print(f\"Backprop node {node.state}, visits={node.visits}, value={node.value}\")\n",
    "            node = node.parent\n",
    "\n",
    "\n",
    "# --- MCTS Search Class ---\n",
    "class MCTS:\n",
    "    def __init__(self, make_env, num_iterations=100, num_simulations=10, exploration=1.41, verbose=False):\n",
    "        self.make_env = make_env\n",
    "        self.env = make_env()\n",
    "        self.root = MCTSNode(self.env.reset()[0], make_env=self.make_env, verbose=verbose)\n",
    "        self.num_iterations = num_iterations\n",
    "        self.num_simulations = num_simulations\n",
    "        self.exploration = exploration\n",
    "        self.verbose = verbose\n",
    "        self.root.expand(self.env)\n",
    "\n",
    "    def run(self):\n",
    "        for _ in range(self.num_iterations):\n",
    "            node, goal = self.root.selection(self.env)\n",
    "            if goal:\n",
    "                node.backpropagation(1)\n",
    "                if self.verbose:\n",
    "                    print(f\"Goal reached at state {node.state}\")\n",
    "                break\n",
    "            reward = node.simulation(max_steps=self.num_simulations)\n",
    "            node.backpropagation(reward)\n",
    "        if self.verbose:\n",
    "            print(f\"Finished {self.num_iterations} iterations.\")\n",
    "\n",
    "\n",
    "# --- Main Execution ---\n",
    "def make_env():\n",
    "    return gym.make(\"FrozenLake-v1\", is_slippery=False, render_mode=\"ansi\")\n",
    "\n",
    "# Run MCTS\n",
    "mcts = MCTS(make_env=make_env, num_iterations=1000, num_simulations=100, exploration=1.41, verbose=False)\n",
    "mcts.run()\n",
    "\n",
    "# Visualise best path\n",
    "env = make_env()\n",
    "env.reset()\n",
    "print(\"Initial state:\")\n",
    "print(env.render())\n",
    "\n",
    "trajectory = []\n",
    "node = mcts.root\n",
    "trajectory.append((node.state, node.action, node.value))\n",
    "while not node.is_leaf():\n",
    "    prev_node = node\n",
    "    node = prev_node.best_child()\n",
    "    trajectory.append((node.state, node.action, node.value))\n",
    "    print(f\"Best action from state {prev_node.state} to state {node.state} with value {node.value}\")\n",
    "    env.step(node.action)\n",
    "    print(env.render())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, None, 3.0), (4, 1, 3.0), (8, 1, 3.0), (9, 2, 3.0), (13, 1, 2.0), (14, 2, 2.0), (15, 2, 1.0)]\n"
     ]
    }
   ],
   "source": [
    "print(trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
