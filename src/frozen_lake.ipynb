{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCTS implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanded node 0 with children: [4, 1]\n",
      "Simulating from 4 → 5 with action 2 reward 0.0\n",
      "Backprop node 4, visits=1, value=0.0\n",
      "Backprop node 0, visits=1, value=0.0\n",
      "Simulating from 1 → 0 with action 0 reward 0.0\n",
      "Simulating from 1 → 0 with action 3 reward 0.0\n",
      "Simulating from 1 → 0 with action 3 reward 0.0\n",
      "Simulating from 1 → 0 with action 3 reward 0.0\n",
      "Simulating from 1 → 1 with action 2 reward 0.0\n",
      "Simulating from 1 → 1 with action 3 reward 0.0\n",
      "Simulating from 1 → 1 with action 3 reward 0.0\n",
      "Simulating from 1 → 5 with action 1 reward 0.0\n",
      "Backprop node 1, visits=1, value=0.0\n",
      "Backprop node 0, visits=2, value=0.0\n",
      "Expanded node 4 with children: [8, 0]\n",
      "Simulating from 8 → 9 with action 2 reward 0.0\n",
      "Simulating from 8 → 5 with action 3 reward 0.0\n",
      "Backprop node 8, visits=1, value=0.0\n",
      "Backprop node 4, visits=2, value=0.0\n",
      "Backprop node 0, visits=3, value=0.0\n",
      "Expanded node 1 with children: [0, 2]\n",
      "Simulating from 2 → 1 with action 0 reward 0.0\n",
      "Simulating from 2 → 2 with action 2 reward 0.0\n",
      "Simulating from 2 → 6 with action 1 reward 0.0\n",
      "Simulating from 2 → 5 with action 0 reward 0.0\n",
      "Backprop node 2, visits=1, value=0.0\n",
      "Backprop node 1, visits=2, value=0.0\n",
      "Backprop node 0, visits=4, value=0.0\n",
      "Simulating from 0 → 0 with action 3 reward 0.0\n",
      "Simulating from 0 → 4 with action 1 reward 0.0\n",
      "Simulating from 0 → 5 with action 2 reward 0.0\n",
      "Backprop node 0, visits=1, value=0.0\n",
      "Backprop node 4, visits=3, value=0.0\n",
      "Backprop node 0, visits=5, value=0.0\n",
      "Simulating from 0 → 0 with action 3 reward 0.0\n",
      "Simulating from 0 → 4 with action 1 reward 0.0\n",
      "Simulating from 0 → 4 with action 0 reward 0.0\n",
      "Simulating from 0 → 5 with action 2 reward 0.0\n",
      "Backprop node 0, visits=1, value=0.0\n",
      "Backprop node 1, visits=3, value=0.0\n",
      "Backprop node 0, visits=6, value=0.0\n",
      "Expanded node 8 with children: [9, 4]\n",
      "Simulating from 9 → 13 with action 1 reward 0.0\n",
      "Simulating from 9 → 13 with action 1 reward 0.0\n",
      "Simulating from 9 → 14 with action 2 reward 0.0\n",
      "Simulating from 9 → 13 with action 0 reward 0.0\n",
      "Simulating from 9 → 9 with action 3 reward 0.0\n",
      "Simulating from 9 → 5 with action 3 reward 0.0\n",
      "Backprop node 9, visits=1, value=0.0\n",
      "Backprop node 8, visits=2, value=0.0\n",
      "Backprop node 4, visits=4, value=0.0\n",
      "Backprop node 0, visits=7, value=0.0\n",
      "Expanded node 0 with children: [4, 1]\n",
      "Simulating from 1 → 1 with action 3 reward 0.0\n",
      "Simulating from 1 → 2 with action 2 reward 0.0\n",
      "Simulating from 1 → 3 with action 2 reward 0.0\n",
      "Simulating from 1 → 3 with action 2 reward 0.0\n",
      "Simulating from 1 → 3 with action 2 reward 0.0\n",
      "Simulating from 1 → 3 with action 3 reward 0.0\n",
      "Simulating from 1 → 3 with action 3 reward 0.0\n",
      "Simulating from 1 → 2 with action 0 reward 0.0\n",
      "Simulating from 1 → 3 with action 2 reward 0.0\n",
      "Simulating from 1 → 7 with action 1 reward 0.0\n",
      "Backprop node 1, visits=1, value=0.0\n",
      "Backprop node 0, visits=2, value=0.0\n",
      "Backprop node 1, visits=4, value=0.0\n",
      "Backprop node 0, visits=8, value=0.0\n",
      "Expanded node 0 with children: [4, 1]\n",
      "Simulating from 1 → 5 with action 1 reward 0.0\n",
      "Backprop node 1, visits=1, value=0.0\n",
      "Backprop node 0, visits=2, value=0.0\n",
      "Backprop node 4, visits=5, value=0.0\n",
      "Backprop node 0, visits=9, value=0.0\n",
      "Expanded node 2 with children: [1, 6, 3]\n",
      "Simulating from 6 → 7 with action 2 reward 0.0\n",
      "Backprop node 6, visits=1, value=0.0\n",
      "Backprop node 2, visits=2, value=0.0\n",
      "Backprop node 1, visits=5, value=0.0\n",
      "Backprop node 0, visits=10, value=0.0\n",
      "Simulating from 4 → 4 with action 0 reward 0.0\n",
      "Simulating from 4 → 8 with action 1 reward 0.0\n",
      "Simulating from 4 → 9 with action 2 reward 0.0\n",
      "Simulating from 4 → 10 with action 2 reward 0.0\n",
      "Simulating from 4 → 14 with action 1 reward 0.0\n",
      "Simulating from 4 → 14 with action 1 reward 0.0\n",
      "Simulating from 4 → 10 with action 3 reward 0.0\n",
      "Simulating from 4 → 9 with action 0 reward 0.0\n",
      "Simulating from 4 → 10 with action 2 reward 0.0\n",
      "Simulating from 4 → 6 with action 3 reward 0.0\n",
      "Simulating from 4 → 2 with action 3 reward 0.0\n",
      "Simulating from 4 → 6 with action 1 reward 0.0\n",
      "Simulating from 4 → 5 with action 0 reward 0.0\n",
      "Backprop node 4, visits=1, value=0.0\n",
      "Backprop node 8, visits=3, value=0.0\n",
      "Backprop node 4, visits=6, value=0.0\n",
      "Backprop node 0, visits=11, value=0.0\n",
      "Simulating from 4 → 8 with action 1 reward 0.0\n",
      "Simulating from 4 → 12 with action 1 reward 0.0\n",
      "Backprop node 4, visits=1, value=0.0\n",
      "Backprop node 0, visits=3, value=0.0\n",
      "Backprop node 1, visits=6, value=0.0\n",
      "Backprop node 0, visits=12, value=0.0\n",
      "Simulating from 4 → 0 with action 3 reward 0.0\n",
      "Simulating from 4 → 0 with action 3 reward 0.0\n",
      "Simulating from 4 → 0 with action 0 reward 0.0\n",
      "Simulating from 4 → 0 with action 3 reward 0.0\n",
      "Simulating from 4 → 4 with action 1 reward 0.0\n",
      "Simulating from 4 → 4 with action 0 reward 0.0\n",
      "Simulating from 4 → 5 with action 2 reward 0.0\n",
      "Backprop node 4, visits=1, value=0.0\n",
      "Backprop node 0, visits=3, value=0.0\n",
      "Backprop node 4, visits=7, value=0.0\n",
      "Backprop node 0, visits=13, value=0.0\n",
      "Simulating from 1 → 2 with action 2 reward 0.0\n",
      "Simulating from 1 → 6 with action 1 reward 0.0\n",
      "Simulating from 1 → 7 with action 2 reward 0.0\n",
      "Backprop node 1, visits=1, value=0.0\n",
      "Backprop node 2, visits=3, value=0.0\n",
      "Backprop node 1, visits=7, value=0.0\n",
      "Backprop node 0, visits=14, value=0.0\n",
      "Expanded node 9 with children: [8, 13, 10]\n",
      "Simulating from 8 → 8 with action 0 reward 0.0\n",
      "Simulating from 8 → 4 with action 3 reward 0.0\n",
      "Simulating from 8 → 8 with action 1 reward 0.0\n",
      "Simulating from 8 → 12 with action 1 reward 0.0\n",
      "Backprop node 8, visits=1, value=0.0\n",
      "Backprop node 9, visits=2, value=0.0\n",
      "Backprop node 8, visits=4, value=0.0\n",
      "Backprop node 4, visits=8, value=0.0\n",
      "Backprop node 0, visits=15, value=0.0\n",
      "Expanded node 4 with children: [8, 0]\n",
      "Simulating from 0 → 0 with action 3 reward 0.0\n",
      "Simulating from 0 → 4 with action 1 reward 0.0\n",
      "Simulating from 0 → 0 with action 3 reward 0.0\n",
      "Simulating from 0 → 0 with action 3 reward 0.0\n",
      "Simulating from 0 → 4 with action 1 reward 0.0\n",
      "Simulating from 0 → 5 with action 2 reward 0.0\n",
      "Backprop node 0, visits=1, value=0.0\n",
      "Backprop node 4, visits=2, value=0.0\n",
      "Backprop node 0, visits=4, value=0.0\n",
      "Backprop node 1, visits=8, value=0.0\n",
      "Backprop node 0, visits=16, value=0.0\n",
      "Expanded node 4 with children: [8, 0]\n",
      "Simulating from 8 → 9 with action 2 reward 0.0\n",
      "Simulating from 8 → 13 with action 1 reward 0.0\n",
      "Simulating from 8 → 13 with action 1 reward 0.0\n",
      "Simulating from 8 → 13 with action 1 reward 0.0\n",
      "Simulating from 8 → 14 with action 2 reward 0.0\n",
      "Simulating from 8 → 13 with action 0 reward 0.0\n",
      "Simulating from 8 → 12 with action 0 reward 0.0\n",
      "Backprop node 8, visits=1, value=0.0\n",
      "Backprop node 4, visits=2, value=0.0\n",
      "Backprop node 0, visits=4, value=0.0\n",
      "Backprop node 4, visits=9, value=0.0\n",
      "Backprop node 0, visits=17, value=0.0\n",
      "Simulating from 3 → 2 with action 0 reward 0.0\n",
      "Simulating from 3 → 3 with action 2 reward 0.0\n",
      "Simulating from 3 → 7 with action 1 reward 0.0\n",
      "Backprop node 3, visits=1, value=0.0\n",
      "Backprop node 2, visits=4, value=0.0\n",
      "Backprop node 1, visits=9, value=0.0\n",
      "Backprop node 0, visits=18, value=0.0\n",
      "Expanded node 4 with children: [8, 0]\n",
      "Simulating from 0 → 1 with action 2 reward 0.0\n",
      "Simulating from 0 → 5 with action 1 reward 0.0\n",
      "Backprop node 0, visits=1, value=0.0\n",
      "Backprop node 4, visits=2, value=0.0\n",
      "Backprop node 8, visits=5, value=0.0\n",
      "Backprop node 4, visits=10, value=0.0\n",
      "Backprop node 0, visits=19, value=0.0\n",
      "Expanded node 1 with children: [0, 2]\n",
      "Simulating from 2 → 1 with action 0 reward 0.0\n",
      "Simulating from 2 → 1 with action 3 reward 0.0\n",
      "Simulating from 2 → 1 with action 3 reward 0.0\n",
      "Simulating from 2 → 0 with action 0 reward 0.0\n",
      "Simulating from 2 → 4 with action 1 reward 0.0\n",
      "Simulating from 2 → 5 with action 2 reward 0.0\n",
      "Backprop node 2, visits=1, value=0.0\n",
      "Backprop node 1, visits=2, value=0.0\n",
      "Backprop node 0, visits=5, value=0.0\n",
      "Backprop node 1, visits=10, value=0.0\n",
      "Backprop node 0, visits=20, value=0.0\n",
      "Expanded node 1 with children: [0, 2]\n",
      "Simulating from 2 → 2 with action 3 reward 0.0\n",
      "Simulating from 2 → 2 with action 3 reward 0.0\n",
      "Simulating from 2 → 1 with action 0 reward 0.0\n",
      "Simulating from 2 → 5 with action 1 reward 0.0\n",
      "Backprop node 2, visits=1, value=0.0\n",
      "Backprop node 1, visits=2, value=0.0\n",
      "Backprop node 0, visits=5, value=0.0\n",
      "Backprop node 4, visits=11, value=0.0\n",
      "Backprop node 0, visits=21, value=0.0\n",
      "Expanded node 1 with children: [0, 2]\n",
      "Simulating from 2 → 3 with action 2 reward 0.0\n",
      "Simulating from 2 → 2 with action 0 reward 0.0\n",
      "Simulating from 2 → 6 with action 1 reward 0.0\n",
      "Simulating from 2 → 7 with action 2 reward 0.0\n",
      "Backprop node 2, visits=1, value=0.0\n",
      "Backprop node 1, visits=2, value=0.0\n",
      "Backprop node 2, visits=5, value=0.0\n",
      "Backprop node 1, visits=11, value=0.0\n",
      "Backprop node 0, visits=22, value=0.0\n",
      "Simulating from 13 → 9 with action 3 reward 0.0\n",
      "Simulating from 13 → 5 with action 3 reward 0.0\n",
      "Backprop node 13, visits=1, value=0.0\n",
      "Backprop node 9, visits=3, value=0.0\n",
      "Backprop node 8, visits=6, value=0.0\n",
      "Backprop node 4, visits=12, value=0.0\n",
      "Backprop node 0, visits=23, value=0.0\n",
      "Simulating from 8 → 4 with action 3 reward 0.0\n",
      "Simulating from 8 → 5 with action 2 reward 0.0\n",
      "Backprop node 8, visits=1, value=0.0\n",
      "Backprop node 4, visits=3, value=0.0\n",
      "Backprop node 0, visits=6, value=0.0\n",
      "Backprop node 1, visits=12, value=0.0\n",
      "Backprop node 0, visits=24, value=0.0\n",
      "Simulating from 0 → 1 with action 2 reward 0.0\n",
      "Simulating from 0 → 1 with action 3 reward 0.0\n",
      "Simulating from 0 → 5 with action 1 reward 0.0\n",
      "Backprop node 0, visits=1, value=0.0\n",
      "Backprop node 4, visits=3, value=0.0\n",
      "Backprop node 0, visits=6, value=0.0\n",
      "Backprop node 4, visits=13, value=0.0\n",
      "Backprop node 0, visits=25, value=0.0\n",
      "Expanded node 6 with children: [10, 2]\n",
      "Simulating from 10 → 14 with action 1 reward 0.0\n",
      "Simulating from 10 → 10 with action 3 reward 0.0\n",
      "Simulating from 10 → 9 with action 0 reward 0.0\n",
      "Simulating from 10 → 8 with action 0 reward 0.0\n",
      "Simulating from 10 → 9 with action 2 reward 0.0\n",
      "Simulating from 10 → 10 with action 2 reward 0.0\n",
      "Simulating from 10 → 6 with action 3 reward 0.0\n",
      "Simulating from 10 → 10 with action 1 reward 0.0\n",
      "Simulating from 10 → 9 with action 0 reward 0.0\n",
      "Simulating from 10 → 13 with action 1 reward 0.0\n",
      "Simulating from 10 → 9 with action 3 reward 0.0\n",
      "Simulating from 10 → 8 with action 0 reward 0.0\n",
      "Simulating from 10 → 9 with action 2 reward 0.0\n",
      "Simulating from 10 → 5 with action 3 reward 0.0\n",
      "Backprop node 10, visits=1, value=0.0\n",
      "Backprop node 6, visits=2, value=0.0\n",
      "Backprop node 2, visits=6, value=0.0\n",
      "Backprop node 1, visits=13, value=0.0\n",
      "Backprop node 0, visits=26, value=0.0\n",
      "Simulating from 8 → 4 with action 3 reward 0.0\n",
      "Simulating from 8 → 8 with action 1 reward 0.0\n",
      "Simulating from 8 → 12 with action 1 reward 0.0\n",
      "Backprop node 8, visits=1, value=0.0\n",
      "Backprop node 4, visits=3, value=0.0\n",
      "Backprop node 8, visits=7, value=0.0\n",
      "Backprop node 4, visits=14, value=0.0\n",
      "Backprop node 0, visits=27, value=0.0\n",
      "Simulating from 0 → 0 with action 3 reward 0.0\n",
      "Simulating from 0 → 0 with action 0 reward 0.0\n",
      "Simulating from 0 → 0 with action 3 reward 0.0\n",
      "Simulating from 0 → 4 with action 1 reward 0.0\n",
      "Simulating from 0 → 4 with action 0 reward 0.0\n",
      "Simulating from 0 → 8 with action 1 reward 0.0\n",
      "Simulating from 0 → 12 with action 1 reward 0.0\n",
      "Backprop node 0, visits=1, value=0.0\n",
      "Backprop node 1, visits=3, value=0.0\n",
      "Backprop node 0, visits=7, value=0.0\n",
      "Backprop node 1, visits=14, value=0.0\n",
      "Backprop node 0, visits=28, value=0.0\n",
      "Simulating from 0 → 1 with action 2 reward 0.0\n",
      "Simulating from 0 → 2 with action 2 reward 0.0\n",
      "Simulating from 0 → 3 with action 2 reward 0.0\n",
      "Simulating from 0 → 2 with action 0 reward 0.0\n",
      "Simulating from 0 → 3 with action 2 reward 0.0\n",
      "Simulating from 0 → 7 with action 1 reward 0.0\n",
      "Backprop node 0, visits=1, value=0.0\n",
      "Backprop node 1, visits=3, value=0.0\n",
      "Backprop node 0, visits=7, value=0.0\n",
      "Backprop node 4, visits=15, value=0.0\n",
      "Backprop node 0, visits=29, value=0.0\n",
      "Expanded node 3 with children: [2]\n",
      "Simulating from 2 → 2 with action 3 reward 0.0\n",
      "Simulating from 2 → 3 with action 2 reward 0.0\n",
      "Simulating from 2 → 2 with action 0 reward 0.0\n",
      "Simulating from 2 → 6 with action 1 reward 0.0\n",
      "Simulating from 2 → 7 with action 2 reward 0.0\n",
      "Backprop node 2, visits=1, value=0.0\n",
      "Backprop node 3, visits=2, value=0.0\n",
      "Backprop node 2, visits=7, value=0.0\n",
      "Backprop node 1, visits=15, value=0.0\n",
      "Backprop node 0, visits=30, value=0.0\n",
      "Simulating from 10 → 14 with action 1 reward 0.0\n",
      "Simulating from 10 → 15 with action 2 reward 1.0\n",
      "Backprop node 10, visits=1, value=1.0\n",
      "Backprop node 9, visits=4, value=1.0\n",
      "Backprop node 8, visits=8, value=1.0\n",
      "Backprop node 4, visits=16, value=1.0\n",
      "Backprop node 0, visits=31, value=1.0\n",
      "Expanded node 10 with children: [9, 14, 6]\n",
      "Simulating from 9 → 13 with action 1 reward 0.0\n",
      "Simulating from 9 → 13 with action 1 reward 0.0\n",
      "Simulating from 9 → 14 with action 2 reward 0.0\n",
      "Simulating from 9 → 10 with action 3 reward 0.0\n",
      "Simulating from 9 → 11 with action 2 reward 0.0\n",
      "Backprop node 9, visits=1, value=0.0\n",
      "Backprop node 10, visits=2, value=1.0\n",
      "Backprop node 9, visits=5, value=1.0\n",
      "Backprop node 8, visits=9, value=1.0\n",
      "Backprop node 4, visits=17, value=1.0\n",
      "Backprop node 0, visits=32, value=1.0\n",
      "Expanded node 8 with children: [9, 4]\n",
      "Simulating from 4 → 4 with action 0 reward 0.0\n",
      "Simulating from 4 → 0 with action 3 reward 0.0\n",
      "Simulating from 4 → 4 with action 1 reward 0.0\n",
      "Simulating from 4 → 8 with action 1 reward 0.0\n",
      "Simulating from 4 → 9 with action 2 reward 0.0\n",
      "Simulating from 4 → 5 with action 3 reward 0.0\n",
      "Backprop node 4, visits=1, value=0.0\n",
      "Backprop node 8, visits=2, value=0.0\n",
      "Backprop node 4, visits=4, value=0.0\n",
      "Backprop node 8, visits=10, value=1.0\n",
      "Backprop node 4, visits=18, value=1.0\n",
      "Backprop node 0, visits=33, value=1.0\n",
      "Expanded node 8 with children: [9, 4]\n",
      "Simulating from 9 → 8 with action 0 reward 0.0\n",
      "Simulating from 9 → 4 with action 3 reward 0.0\n",
      "Simulating from 9 → 0 with action 3 reward 0.0\n",
      "Simulating from 9 → 4 with action 1 reward 0.0\n",
      "Simulating from 9 → 0 with action 3 reward 0.0\n",
      "Simulating from 9 → 1 with action 2 reward 0.0\n",
      "Simulating from 9 → 0 with action 0 reward 0.0\n",
      "Simulating from 9 → 0 with action 3 reward 0.0\n",
      "Simulating from 9 → 0 with action 0 reward 0.0\n",
      "Simulating from 9 → 0 with action 3 reward 0.0\n",
      "Simulating from 9 → 4 with action 1 reward 0.0\n",
      "Simulating from 9 → 8 with action 1 reward 0.0\n",
      "Simulating from 9 → 12 with action 1 reward 0.0\n",
      "Backprop node 9, visits=1, value=0.0\n",
      "Backprop node 8, visits=2, value=0.0\n",
      "Backprop node 4, visits=4, value=0.0\n",
      "Backprop node 0, visits=8, value=0.0\n",
      "Backprop node 1, visits=16, value=0.0\n",
      "Backprop node 0, visits=34, value=1.0\n",
      "Expanded node 8 with children: [9, 4]\n",
      "Simulating from 4 → 8 with action 1 reward 0.0\n",
      "Simulating from 4 → 12 with action 1 reward 0.0\n",
      "Backprop node 4, visits=1, value=0.0\n",
      "Backprop node 8, visits=2, value=0.0\n",
      "Backprop node 4, visits=4, value=0.0\n",
      "Backprop node 0, visits=8, value=0.0\n",
      "Backprop node 4, visits=19, value=1.0\n",
      "Backprop node 0, visits=35, value=1.0\n",
      "Simulating from 0 → 0 with action 3 reward 0.0\n",
      "Simulating from 0 → 0 with action 0 reward 0.0\n",
      "Simulating from 0 → 0 with action 3 reward 0.0\n",
      "Simulating from 0 → 0 with action 3 reward 0.0\n",
      "Simulating from 0 → 0 with action 3 reward 0.0\n",
      "Simulating from 0 → 0 with action 0 reward 0.0\n",
      "Simulating from 0 → 1 with action 2 reward 0.0\n",
      "Simulating from 0 → 1 with action 3 reward 0.0\n",
      "Simulating from 0 → 5 with action 1 reward 0.0\n",
      "Backprop node 0, visits=1, value=0.0\n",
      "Backprop node 1, visits=3, value=0.0\n",
      "Backprop node 2, visits=8, value=0.0\n",
      "Backprop node 1, visits=17, value=0.0\n",
      "Backprop node 0, visits=36, value=1.0\n",
      "Expanded node 8 with children: [9, 4]\n",
      "Simulating from 4 → 0 with action 3 reward 0.0\n",
      "Simulating from 4 → 1 with action 2 reward 0.0\n",
      "Simulating from 4 → 5 with action 1 reward 0.0\n",
      "Backprop node 4, visits=1, value=0.0\n",
      "Backprop node 8, visits=2, value=0.0\n",
      "Backprop node 9, visits=6, value=1.0\n",
      "Backprop node 8, visits=11, value=1.0\n",
      "Backprop node 4, visits=20, value=1.0\n",
      "Backprop node 0, visits=37, value=1.0\n",
      "Expanded node 0 with children: [4, 1]\n",
      "Simulating from 1 → 2 with action 2 reward 0.0\n",
      "Simulating from 1 → 2 with action 3 reward 0.0\n",
      "Simulating from 1 → 1 with action 0 reward 0.0\n",
      "Simulating from 1 → 1 with action 3 reward 0.0\n",
      "Simulating from 1 → 0 with action 0 reward 0.0\n",
      "Simulating from 1 → 1 with action 2 reward 0.0\n",
      "Simulating from 1 → 1 with action 3 reward 0.0\n",
      "Simulating from 1 → 1 with action 3 reward 0.0\n",
      "Simulating from 1 → 5 with action 1 reward 0.0\n",
      "Backprop node 1, visits=1, value=0.0\n",
      "Backprop node 0, visits=2, value=0.0\n",
      "Backprop node 1, visits=4, value=0.0\n",
      "Backprop node 0, visits=9, value=0.0\n",
      "Backprop node 1, visits=18, value=0.0\n",
      "Backprop node 0, visits=38, value=1.0\n",
      "Expanded node 0 with children: [4, 1]\n",
      "Simulating from 4 → 4 with action 0 reward 0.0\n",
      "Simulating from 4 → 0 with action 3 reward 0.0\n",
      "Simulating from 4 → 4 with action 1 reward 0.0\n",
      "Simulating from 4 → 5 with action 2 reward 0.0\n",
      "Backprop node 4, visits=1, value=0.0\n",
      "Backprop node 0, visits=2, value=0.0\n",
      "Backprop node 1, visits=4, value=0.0\n",
      "Backprop node 0, visits=9, value=0.0\n",
      "Backprop node 4, visits=21, value=1.0\n",
      "Backprop node 0, visits=39, value=1.0\n",
      "Expanded node 0 with children: [4, 1]\n",
      "Simulating from 4 → 4 with action 0 reward 0.0\n",
      "Simulating from 4 → 4 with action 0 reward 0.0\n",
      "Simulating from 4 → 4 with action 0 reward 0.0\n",
      "Simulating from 4 → 8 with action 1 reward 0.0\n",
      "Simulating from 4 → 9 with action 2 reward 0.0\n",
      "Simulating from 4 → 13 with action 1 reward 0.0\n",
      "Simulating from 4 → 12 with action 0 reward 0.0\n",
      "Backprop node 4, visits=1, value=0.0\n",
      "Backprop node 0, visits=2, value=0.0\n",
      "Backprop node 4, visits=5, value=0.0\n",
      "Backprop node 8, visits=12, value=1.0\n",
      "Backprop node 4, visits=22, value=1.0\n",
      "Backprop node 0, visits=40, value=1.0\n",
      "Simulating from 2 → 1 with action 0 reward 0.0\n",
      "Simulating from 2 → 0 with action 0 reward 0.0\n",
      "Simulating from 2 → 4 with action 1 reward 0.0\n",
      "Simulating from 2 → 4 with action 0 reward 0.0\n",
      "Simulating from 2 → 0 with action 3 reward 0.0\n",
      "Simulating from 2 → 0 with action 3 reward 0.0\n",
      "Simulating from 2 → 0 with action 3 reward 0.0\n",
      "Simulating from 2 → 0 with action 3 reward 0.0\n",
      "Simulating from 2 → 0 with action 0 reward 0.0\n",
      "Simulating from 2 → 1 with action 2 reward 0.0\n",
      "Simulating from 2 → 1 with action 3 reward 0.0\n",
      "Simulating from 2 → 5 with action 1 reward 0.0\n",
      "Backprop node 2, visits=1, value=0.0\n",
      "Backprop node 6, visits=3, value=0.0\n",
      "Backprop node 2, visits=9, value=0.0\n",
      "Backprop node 1, visits=19, value=0.0\n",
      "Backprop node 0, visits=41, value=1.0\n",
      "Expanded node 0 with children: [4, 1]\n",
      "Simulating from 1 → 1 with action 3 reward 0.0\n",
      "Simulating from 1 → 5 with action 1 reward 0.0\n",
      "Backprop node 1, visits=1, value=0.0\n",
      "Backprop node 0, visits=2, value=0.0\n",
      "Backprop node 4, visits=5, value=0.0\n",
      "Backprop node 0, visits=10, value=0.0\n",
      "Backprop node 4, visits=23, value=1.0\n",
      "Backprop node 0, visits=42, value=1.0\n",
      "Expanded node 0 with children: [4, 1]\n",
      "Simulating from 1 → 5 with action 1 reward 0.0\n",
      "Backprop node 1, visits=1, value=0.0\n",
      "Backprop node 0, visits=2, value=0.0\n",
      "Backprop node 4, visits=5, value=0.0\n",
      "Backprop node 0, visits=10, value=0.0\n",
      "Backprop node 1, visits=20, value=0.0\n",
      "Backprop node 0, visits=43, value=1.0\n",
      "Expanded node 13 with children: [14, 9]\n",
      "Simulating from 9 → 5 with action 3 reward 0.0\n",
      "Backprop node 9, visits=1, value=0.0\n",
      "Backprop node 13, visits=2, value=0.0\n",
      "Backprop node 9, visits=7, value=1.0\n",
      "Backprop node 8, visits=13, value=1.0\n",
      "Backprop node 4, visits=24, value=1.0\n",
      "Backprop node 0, visits=44, value=1.0\n",
      "Expanded node 2 with children: [1, 6, 3]\n",
      "Simulating from 1 → 5 with action 1 reward 0.0\n",
      "Backprop node 1, visits=1, value=0.0\n",
      "Backprop node 2, visits=2, value=0.0\n",
      "Backprop node 3, visits=3, value=0.0\n",
      "Backprop node 2, visits=10, value=0.0\n",
      "Backprop node 1, visits=21, value=0.0\n",
      "Backprop node 0, visits=45, value=1.0\n",
      "Expanded node 2 with children: [1, 6, 3]\n",
      "Simulating from 1 → 2 with action 2 reward 0.0\n",
      "Simulating from 1 → 2 with action 3 reward 0.0\n",
      "Simulating from 1 → 6 with action 1 reward 0.0\n",
      "Simulating from 1 → 10 with action 1 reward 0.0\n",
      "Simulating from 1 → 11 with action 2 reward 0.0\n",
      "Backprop node 1, visits=1, value=0.0\n",
      "Backprop node 2, visits=2, value=0.0\n",
      "Backprop node 1, visits=5, value=0.0\n",
      "Backprop node 0, visits=11, value=0.0\n",
      "Backprop node 4, visits=25, value=1.0\n",
      "Backprop node 0, visits=46, value=1.0\n",
      "Expanded node 2 with children: [1, 6, 3]\n",
      "Simulating from 6 → 10 with action 1 reward 0.0\n",
      "Simulating from 6 → 9 with action 0 reward 0.0\n",
      "Simulating from 6 → 13 with action 1 reward 0.0\n",
      "Simulating from 6 → 13 with action 1 reward 0.0\n",
      "Simulating from 6 → 9 with action 3 reward 0.0\n",
      "Simulating from 6 → 8 with action 0 reward 0.0\n",
      "Simulating from 6 → 8 with action 0 reward 0.0\n",
      "Simulating from 6 → 8 with action 0 reward 0.0\n",
      "Simulating from 6 → 9 with action 2 reward 0.0\n",
      "Simulating from 6 → 5 with action 3 reward 0.0\n",
      "Backprop node 6, visits=1, value=0.0\n",
      "Backprop node 2, visits=2, value=0.0\n",
      "Backprop node 1, visits=5, value=0.0\n",
      "Backprop node 0, visits=11, value=0.0\n",
      "Backprop node 1, visits=22, value=0.0\n",
      "Backprop node 0, visits=47, value=1.0\n",
      "Simulating from 9 → 13 with action 1 reward 0.0\n",
      "Simulating from 9 → 9 with action 3 reward 0.0\n",
      "Simulating from 9 → 10 with action 2 reward 0.0\n",
      "Simulating from 9 → 14 with action 1 reward 0.0\n",
      "Simulating from 9 → 10 with action 3 reward 0.0\n",
      "Simulating from 9 → 9 with action 0 reward 0.0\n",
      "Simulating from 9 → 5 with action 3 reward 0.0\n",
      "Backprop node 9, visits=1, value=0.0\n",
      "Backprop node 8, visits=3, value=0.0\n",
      "Backprop node 4, visits=6, value=0.0\n",
      "Backprop node 8, visits=14, value=1.0\n",
      "Backprop node 4, visits=26, value=1.0\n",
      "Backprop node 0, visits=48, value=1.0\n",
      "Expanded node 0 with children: [4, 1]\n",
      "Simulating from 4 → 8 with action 1 reward 0.0\n",
      "Simulating from 4 → 8 with action 0 reward 0.0\n",
      "Simulating from 4 → 4 with action 3 reward 0.0\n",
      "Simulating from 4 → 5 with action 2 reward 0.0\n",
      "Backprop node 4, visits=1, value=0.0\n",
      "Backprop node 0, visits=2, value=0.0\n",
      "Backprop node 1, visits=4, value=0.0\n",
      "Backprop node 2, visits=11, value=0.0\n",
      "Backprop node 1, visits=23, value=0.0\n",
      "Backprop node 0, visits=49, value=1.0\n",
      "Simulating from 9 → 13 with action 1 reward 0.0\n",
      "Simulating from 9 → 12 with action 0 reward 0.0\n",
      "Backprop node 9, visits=1, value=0.0\n",
      "Backprop node 8, visits=3, value=0.0\n",
      "Backprop node 4, visits=6, value=0.0\n",
      "Backprop node 0, visits=12, value=0.0\n",
      "Backprop node 4, visits=27, value=1.0\n",
      "Backprop node 0, visits=50, value=1.0\n",
      "Simulating from 4 → 4 with action 0 reward 0.0\n",
      "Simulating from 4 → 8 with action 1 reward 0.0\n",
      "Simulating from 4 → 4 with action 3 reward 0.0\n",
      "Simulating from 4 → 5 with action 2 reward 0.0\n",
      "Backprop node 4, visits=1, value=0.0\n",
      "Backprop node 8, visits=3, value=0.0\n",
      "Backprop node 4, visits=6, value=0.0\n",
      "Backprop node 0, visits=12, value=0.0\n",
      "Backprop node 1, visits=24, value=0.0\n",
      "Backprop node 0, visits=51, value=1.0\n",
      "Simulating from 14 → 15 with action 2 reward 1.0\n",
      "Backprop node 14, visits=1, value=1.0\n",
      "Backprop node 10, visits=3, value=2.0\n",
      "Backprop node 9, visits=8, value=2.0\n",
      "Backprop node 8, visits=15, value=2.0\n",
      "Backprop node 4, visits=28, value=2.0\n",
      "Backprop node 0, visits=52, value=2.0\n",
      "Simulating from 6 → 7 with action 2 reward 0.0\n",
      "Backprop node 6, visits=1, value=0.0\n",
      "Backprop node 10, visits=4, value=2.0\n",
      "Backprop node 9, visits=9, value=2.0\n",
      "Backprop node 8, visits=16, value=2.0\n",
      "Backprop node 4, visits=29, value=2.0\n",
      "Backprop node 0, visits=53, value=2.0\n",
      "Goal found from state 14 with action 2 → 15\n",
      "Backprop node 15, visits=1, value=1.0\n",
      "Backprop node 14, visits=2, value=2.0\n",
      "Backprop node 10, visits=5, value=3.0\n",
      "Backprop node 9, visits=10, value=3.0\n",
      "Backprop node 8, visits=17, value=3.0\n",
      "Backprop node 4, visits=30, value=3.0\n",
      "Backprop node 0, visits=54, value=3.0\n",
      "Goal reached at state 15\n",
      "Finished 1000 iterations.\n",
      "Initial state:\n",
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "\n",
      "Best action from state 0 to state 4 with value 3.0\n",
      "  (Down)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "\n",
      "Best action from state 4 to state 8 with value 3.0\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "\n",
      "Best action from state 8 to state 9 with value 3.0\n",
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "F\u001b[41mF\u001b[0mFH\n",
      "HFFG\n",
      "\n",
      "Best action from state 9 to state 10 with value 3.0\n",
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "FF\u001b[41mF\u001b[0mH\n",
      "HFFG\n",
      "\n",
      "Best action from state 10 to state 14 with value 2.0\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HF\u001b[41mF\u001b[0mG\n",
      "\n",
      "Best action from state 14 to state 15 with value 1.0\n",
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFF\u001b[41mG\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- MCTS Node Class ---\n",
    "class MCTSNode:\n",
    "    def __init__(self, state, parent=None, action=None, make_env=None, verbose=False):\n",
    "        self.state = state\n",
    "        self.parent = parent\n",
    "        self.action = action\n",
    "        self.children = []\n",
    "        self.visits = 0\n",
    "        self.value = 0.0\n",
    "        self.make_env = make_env\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def is_leaf(self):\n",
    "        return len(self.children) == 0\n",
    "\n",
    "    def uct(self, exploration=1.41):\n",
    "        if self.visits == 0 or self.parent is None:\n",
    "            return float(\"inf\")\n",
    "        exploitation = self.value / self.visits\n",
    "        exploration_bonus = exploration * math.sqrt(math.log(self.parent.visits) / self.visits)\n",
    "        return exploitation + exploration_bonus\n",
    "\n",
    "    def best_uct_child(self):\n",
    "        return max(self.children, key=lambda child: child.uct())\n",
    "\n",
    "    def best_child(self):\n",
    "        return max(self.children, key=lambda child: child.value)\n",
    "\n",
    "    def selection(self, env):\n",
    "        \"\"\"Traverse the tree to select a promising node to expand.\"\"\"\n",
    "        node = self\n",
    "        while not node.is_leaf():\n",
    "            node = node.best_uct_child()\n",
    "        if node.visits == 0:\n",
    "            return node, None\n",
    "        goal_node = node.expand(env)\n",
    "        return (goal_node if goal_node else random.choice(node.children), goal_node is not None)\n",
    "\n",
    "    def expand(self, env):\n",
    "        \"\"\"Expand the node by trying all possible actions.\"\"\"\n",
    "        for action in range(env.action_space.n):\n",
    "            env_copy = self.make_env()\n",
    "            env_copy.reset()\n",
    "            env_copy.unwrapped.s = self.state\n",
    "            obs, reward, terminated, truncated, _ = env_copy.step(action)\n",
    "\n",
    "            if reward == 0 and terminated or self.state == obs:\n",
    "                continue\n",
    "\n",
    "            child = MCTSNode(obs, parent=self, action=action, make_env=self.make_env, verbose=self.verbose)\n",
    "            self.children.append(child)\n",
    "\n",
    "            if reward == 1:\n",
    "                if self.verbose:\n",
    "                    print(f\"Goal found from state {self.state} with action {action} → {obs}\")\n",
    "                return child\n",
    "\n",
    "        if self.verbose:\n",
    "            print(f\"Expanded node {self.state} with children: {[c.state for c in self.children]}\")\n",
    "        return None\n",
    "\n",
    "    def simulation(self, max_steps=10):\n",
    "        \"\"\"Perform a rollout from the current node using random actions.\"\"\"\n",
    "        env_copy = self.make_env()\n",
    "        env_copy.reset()\n",
    "        env_copy.unwrapped.s = self.state\n",
    "        obs = self.state\n",
    "\n",
    "        for _ in range(max_steps):\n",
    "            action = env_copy.action_space.sample()\n",
    "            obs, reward, terminated, truncated, _ = env_copy.step(action)\n",
    "\n",
    "            if self.verbose:\n",
    "                print(f\"Simulating from {self.state} → {obs} with action {action} reward {reward}\")\n",
    "\n",
    "            if reward == 1 or terminated or truncated:\n",
    "                return reward\n",
    "        return 0\n",
    "\n",
    "    def backpropagation(self, reward):\n",
    "        \"\"\"Propagate the simulation result back up the tree.\"\"\"\n",
    "        node = self\n",
    "        while node:\n",
    "            node.visits += 1\n",
    "            node.value += reward\n",
    "            if self.verbose:\n",
    "                print(f\"Backprop node {node.state}, visits={node.visits}, value={node.value}\")\n",
    "            node = node.parent\n",
    "\n",
    "\n",
    "# --- MCTS Search Class ---\n",
    "class MCTS:\n",
    "    def __init__(self, make_env, num_iterations=100, num_simulations=10, exploration=1.41, verbose=False):\n",
    "        self.make_env = make_env\n",
    "        self.env = make_env()\n",
    "        self.root = MCTSNode(self.env.reset()[0], make_env=self.make_env, verbose=verbose)\n",
    "        self.num_iterations = num_iterations\n",
    "        self.num_simulations = num_simulations\n",
    "        self.exploration = exploration\n",
    "        self.verbose = verbose\n",
    "        self.root.expand(self.env)\n",
    "\n",
    "    def run(self):\n",
    "        for _ in range(self.num_iterations):\n",
    "            node, goal = self.root.selection(self.env)\n",
    "            if goal:\n",
    "                node.backpropagation(1)\n",
    "                if self.verbose:\n",
    "                    print(f\"Goal reached at state {node.state}\")\n",
    "                break\n",
    "            reward = node.simulation(max_steps=self.num_simulations)\n",
    "            node.backpropagation(reward)\n",
    "        if self.verbose:\n",
    "            print(f\"Finished {self.num_iterations} iterations.\")\n",
    "\n",
    "\n",
    "# --- Main Execution ---\n",
    "def make_env():\n",
    "    return gym.make(\"FrozenLake-v1\", is_slippery=False, render_mode=\"ansi\")\n",
    "\n",
    "# Run MCTS\n",
    "mcts = MCTS(make_env=make_env, num_iterations=1000, num_simulations=100, exploration=1.41, verbose=False)\n",
    "mcts.run()\n",
    "\n",
    "# Visualise best path\n",
    "env = make_env()\n",
    "env.reset()\n",
    "print(\"Initial state:\")\n",
    "print(env.render())\n",
    "\n",
    "trajectory = []\n",
    "node = mcts.root\n",
    "trajectory.append((node.state, node.action, node.value))\n",
    "while not node.is_leaf():\n",
    "    prev_node = node\n",
    "    node = prev_node.best_child()\n",
    "    trajectory.append((node.state, node.action, node.value))\n",
    "    print(f\"Best action from state {prev_node.state} to state {node.state} with value {node.value}\")\n",
    "    env.step(node.action)\n",
    "    print(env.render())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, None, 3.0), (4, 1, 3.0), (8, 1, 3.0), (9, 2, 3.0), (13, 1, 2.0), (14, 2, 2.0), (15, 2, 1.0)]\n"
     ]
    }
   ],
   "source": [
    "print(trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
